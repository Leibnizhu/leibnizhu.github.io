<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='背景 去年写过一篇 跨Yarn集群提交spark任务 ，是在Spark2.2基础上做的动态提交外部Yarn集群。这里“动态”指不事先将 *-site.xml 打入jar'><title>跨Yarn集群提交spark任务——之Spark2.4坑</title>
<link rel=canonical href=https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/><link rel=stylesheet href=/scss/style.min.23e1d8e9a6160c668989a401c0af6c7e300683648c9edcf1dec562b9b0efc7b4.css><meta property='og:title' content='跨Yarn集群提交spark任务——之Spark2.4坑'><meta property='og:description' content='背景 去年写过一篇 跨Yarn集群提交spark任务 ，是在Spark2.2基础上做的动态提交外部Yarn集群。这里“动态”指不事先将 *-site.xml 打入jar'><meta property='og:url' content='https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/'><meta property='og:site_name' content="Heaven's Door"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Spark'><meta property='article:tag' content='Hadoop'><meta property='article:tag' content='Yarn'><meta property='article:tag' content='跨集群'><meta property='article:published_time' content='2022-05-14T20:33:58+08:00'><meta property='article:modified_time' content='2022-05-14T20:33:58+08:00'><meta property='og:image' content='https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/blackcat.jpeg'><meta name=twitter:title content="跨Yarn集群提交spark任务——之Spark2.4坑"><meta name=twitter:description content="背景 去年写过一篇 跨Yarn集群提交spark任务 ，是在Spark2.2基础上做的动态提交外部Yarn集群。这里“动态”指不事先将 *-site.xml 打入jar"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/blackcat.jpeg'><link rel="shortcut icon" href=favicon.jpg><script async src="https://www.googletagmanager.com/gtag/js?id=G-TK434TCNDK"></script><script>var doNotTrack=!1,dnt;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-TK434TCNDK")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu4af873b90feb2f44d14cf5fcf42d034c_7593_300x0_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Heaven's Door</a></h1><h2 class=site-description>That cold black cloud is comin' down, Feels like I'm knockin' on heaven's door…</h2></div></header><ol class=social-menu><li><a href=/ title=Home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg></a></li><li><a href=https://github.com/leibnizhu target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:leibnizhu@gmail.com target=_blank title=Email><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-gmail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M16 20h3a1 1 0 001-1V5a1 1 0 00-1-1h-3v16z"/><path d="M5 20h3V4H5A1 1 0 004 5v14a1 1 0 001 1z"/><path d="M16 4l-4 4-4-4"/><path d="M4 6.5l8 7.5 8-7.5"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/About/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/Workouts/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-run" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="13" cy="4" r="1"/><path d="M4 17l5 1 .75-1.5"/><path d="M15 21v-4l-4-3 1-6"/><path d="M7 12V9l5-1 3 3 3 1"/></svg>
<span>Workouts</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/Links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://leibnizhu.github.io/ selected>English</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/><img src=/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/blackcat_hu988cee6e86777a2a931b84d96a10c67f_110902_800x0_resize_q75_box.jpeg srcset="/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/blackcat_hu988cee6e86777a2a931b84d96a10c67f_110902_800x0_resize_q75_box.jpeg 800w, /p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/blackcat_hu988cee6e86777a2a931b84d96a10c67f_110902_1600x0_resize_q75_box.jpeg 1600w" width=800 height=419 loading=lazy alt="Featured image of post 跨Yarn集群提交spark任务——之Spark2.4坑"></a></div><div class=article-details><header class=article-category><a href=/categories/Spark/ style=background-color:#2a9d8f;color:#fff>Spark</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/>跨Yarn集群提交spark任务——之Spark2.4坑</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>May 14, 2022</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>6 minute read
</time><time class=article-time--reading>2659 words</time></div></footer></div></header><section class=article-content><h2 id=背景>背景</h2><p>去年写过一篇 <a class=link href=/2021/12/04/%e8%b7%a8Yarn%e9%9b%86%e7%be%a4%e6%8f%90%e4%ba%a4spark%e4%bb%bb%e5%8a%a1/>跨Yarn集群提交spark任务</a> ，是在Spark2.2基础上做的动态提交外部Yarn集群。这里“动态”指不事先将 <code>*-site.xml</code> 打入jar包，而是执行任务时根据配置按需提交到对应集群；而“外部”集群是相对jar包中（如果已有）的 <code>*-site.xml</code> 对应的集群以外的集群，也是在“动态”提交的context中定义的，可以理解为提交到任意网络互通的集群。</p><p>简单回顾下，主要做了两件事情：</p><ol><li>创建SparkContext前，将外部集群的 <code>*-site.xml</code> 放入classpath，如 <code>$PWD</code> 。</li><li>创建SparkContext前，<code>HADOOP_CONF_DIR</code> 和 <code>YARN_CONF_DIR</code> 环境变量改为外部集群 <code>*-site.xml</code> 配置文件所在位置；由于启动java程序后不能直接修改环境变量，在实现上使用了黑魔法。</li></ol><p>时隔半年终于重拾博客，显然又被坑了，没错，之前的方法在Spark2.4里行不通了。</p><h2 id=问题原因分析及解决方案>问题、原因分析、及解决方案</h2><h3 id=spark24中的报错>Spark2.4中的报错</h3><p>在原来代码基础上，升级Spark为2.4.8，执行提交到外部集群的任务，提交到Yarn的AM报错如下：</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Container id: container_e36_1650338235135_41710_02_000001
</span></span><span style=display:flex><span>Exit code: 1
</span></span><span style=display:flex><span>Container exited with a non-zero exit code 1. Error file: prelaunch.err.
</span></span><span style=display:flex><span>Last 4096 bytes of prelaunch.err :
</span></span><span style=display:flex><span>Last 4096 bytes of stderr :
</span></span><span style=display:flex><span>Exception in thread &#34;main&#34; java.lang.IllegalArgumentException: java.net.UnknownHostException: channel
</span></span><span style=display:flex><span>	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374)
</span></span><span style=display:flex><span>	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312)
</span></span><span style=display:flex><span>	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178)
</span></span><span style=display:flex><span>	at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:665)
</span></span><span style=display:flex><span>	at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:601)
</span></span><span style=display:flex><span>	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148)
</span></span><span style=display:flex><span>	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2619)
</span></span><span style=display:flex><span>	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)
</span></span><span style=display:flex><span>	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2653)
</span></span><span style=display:flex><span>	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2635)
</span></span><span style=display:flex><span>	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8$$anonfun$apply$3.apply(ApplicationMaster.scala:219)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8$$anonfun$apply$3.apply(ApplicationMaster.scala:217)
</span></span><span style=display:flex><span>	at scala.Option.foreach(Option.scala:257)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8.apply(ApplicationMaster.scala:217)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8.apply(ApplicationMaster.scala:182)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:780)
</span></span><span style=display:flex><span>	at java.security.AccessController.doPrivileged(Native Method)
</span></span><span style=display:flex><span>	at javax.security.auth.Subject.doAs(Subject.java:422)
</span></span><span style=display:flex><span>	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster.doAsUser(ApplicationMaster.scala:779)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster.&lt;init&gt;(ApplicationMaster.scala:182)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:803)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:834)
</span></span><span style=display:flex><span>	at org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)
</span></span><span style=display:flex><span>Caused by: java.net.UnknownHostException: xxx
</span></span><span style=display:flex><span>	... 25 more
</span></span></code></pre></div><p>其中 <code>xxx</code> 是外部集群的集群名（<code>dfs.nameservices</code> 配置）。</p><h3 id=直接原因分析>直接原因分析</h3><p>仔细观察异常的调用栈，调用到了 <code>NameNodeProxies.createNonHAProxy</code> ，而我们的集群是HA的，显然是读取到的配置不对了。</p><p>看到这个类，阅读过hadoop源码的应该都知道，这是创建 <code>DFSClient</code> 的时候，会先读取 <code>dfs.client.failover.proxy.provider.{hdfs路径对应host}</code> 配置（取值是一个 <code>FailoverProxyProvider</code> 具体实现的全限定类名），反射出Class对象并实例化，然后创建对应的HAProxy；而如果配置为空，则认为NameNode没有开启HA，直接将hdfs路径当作普通host来进行读取，如果实际上这个host是一个HA的nameservices名，不存在这个host，则会报上面的错误。</p><p>所以可以确定，是AM读取不到正确的hdfs配置导致的。那么是为什么呢？</p><p>仔细观察AM的日志，<code>launch_container.sh</code> 里面：</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#776e71>#………………</span>
</span></span><span style=display:flex><span>export <span style=color:#ef6155>HADOOP_YARN_HOME</span><span style=color:#5bc4bf>=</span><span style=color:#f99b15>${</span><span style=color:#ef6155>HADOOP_YARN_HOME</span><span style=color:#815ba4>:-</span><span style=color:#48b685>&#34;/usr/hdp/2.6.5.0-292/hadoop-yarn&#34;</span><span style=color:#f99b15>}</span>
</span></span><span style=display:flex><span>export <span style=color:#ef6155>CLASSPATH</span><span style=color:#5bc4bf>=</span><span style=color:#48b685>&#34;</span><span style=color:#ef6155>$PWD</span><span style=color:#48b685>:</span><span style=color:#ef6155>$PWD</span><span style=color:#48b685>/__spark_conf__:</span><span style=color:#ef6155>$PWD</span><span style=color:#48b685>/__spark_libs__/*:</span><span style=color:#ef6155>$HADOOP_CONF_DIR</span><span style=color:#48b685>:</span><span style=color:#ef6155>$HADOOP_CONF_DIR</span><span style=color:#48b685>:</span><span style=color:#ef6155>$PWD</span><span style=color:#48b685>/__spark_conf__/__hadoop_conf__&#34;</span>
</span></span><span style=display:flex><span>export <span style=color:#ef6155>SPARK_CONF_DIR</span><span style=color:#5bc4bf>=</span><span style=color:#48b685>&#34;/opt/package/spark-2.4.8-bin-hadoop2.6/conf&#34;</span>
</span></span><span style=display:flex><span><span style=color:#776e71>#………………</span>
</span></span></code></pre></div><p>同时注意到 directory.info 记录的目录结构：</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls -l:
</span></span><span style=display:flex><span>total <span style=color:#f99b15>32</span>
</span></span><span style=display:flex><span>-rw-r--r-- <span style=color:#f99b15>1</span> yarn hadoop   <span style=color:#f99b15>71</span> May <span style=color:#f99b15>12</span> 21:18 container_tokens
</span></span><span style=display:flex><span>-rwx------ <span style=color:#f99b15>1</span> yarn hadoop  <span style=color:#f99b15>712</span> May <span style=color:#f99b15>12</span> 21:18 default_container_executor_session.sh
</span></span><span style=display:flex><span>-rwx------ <span style=color:#f99b15>1</span> yarn hadoop  <span style=color:#f99b15>766</span> May <span style=color:#f99b15>12</span> 21:18 default_container_executor.sh
</span></span><span style=display:flex><span>-rwx------ <span style=color:#f99b15>1</span> yarn hadoop <span style=color:#f99b15>5787</span> May <span style=color:#f99b15>12</span> 21:18 launch_container.sh
</span></span><span style=display:flex><span>lrwxrwxrwx <span style=color:#f99b15>1</span> yarn hadoop   <span style=color:#f99b15>80</span> May <span style=color:#f99b15>12</span> 21:18 __spark_conf__ -&gt; /path/to/filecache/29549/__spark_conf__.zip
</span></span><span style=display:flex><span>drwxr-xr-x <span style=color:#f99b15>2</span> yarn hadoop <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>12</span> 21:18 __spark_libs__
</span></span><span style=display:flex><span>drwx--x--- <span style=color:#f99b15>2</span> yarn hadoop <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>12</span> 21:18 tmp
</span></span><span style=display:flex><span>find -L . -maxdepth <span style=color:#f99b15>5</span> -ls:
</span></span><span style=display:flex><span><span style=color:#f99b15>204734730</span>    <span style=color:#f99b15>4</span> drwx--x---   <span style=color:#f99b15>4</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>12</span> 21:18 .
</span></span><span style=display:flex><span><span style=color:#f99b15>204734738</span>    <span style=color:#f99b15>4</span> -rwx------   <span style=color:#f99b15>1</span> yarn     hadoop        <span style=color:#f99b15>766</span> May <span style=color:#f99b15>12</span> 21:18 ./default_container_executor.sh
</span></span><span style=display:flex><span><span style=color:#f99b15>204734734</span>    <span style=color:#f99b15>8</span> -rwx------   <span style=color:#f99b15>1</span> yarn     hadoop       <span style=color:#f99b15>5787</span> May <span style=color:#f99b15>12</span> 21:18 ./launch_container.sh
</span></span><span style=display:flex><span><span style=color:#f99b15>204734733</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>12</span> May <span style=color:#f99b15>12</span> 21:18 ./.container_tokens.crc
</span></span><span style=display:flex><span><span style=color:#f99b15>204734741</span>    <span style=color:#f99b15>4</span> drwxr-xr-x   <span style=color:#f99b15>2</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_libs__
</span></span><span style=display:flex><span><span style=color:#f99b15>105382561</span> <span style=color:#f99b15>555832</span> -r-xr-xr-x   <span style=color:#f99b15>1</span> yarn     hadoop   <span style=color:#f99b15>569170427</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_libs__/mySparkApp.jar
</span></span><span style=display:flex><span><span style=color:#f99b15>204734731</span>    <span style=color:#f99b15>4</span> drwx--x---   <span style=color:#f99b15>2</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>12</span> 21:18 ./tmp
</span></span><span style=display:flex><span><span style=color:#f99b15>204734735</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>56</span> May <span style=color:#f99b15>12</span> 21:18 ./.launch_container.sh.crc
</span></span><span style=display:flex><span><span style=color:#f99b15>204734739</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>16</span> May <span style=color:#f99b15>12</span> 21:18 ./.default_container_executor.sh.crc
</span></span><span style=display:flex><span><span style=color:#f99b15>204734732</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>71</span> May <span style=color:#f99b15>12</span> 21:18 ./container_tokens
</span></span><span style=display:flex><span><span style=color:#f99b15>204734736</span>    <span style=color:#f99b15>4</span> -rwx------   <span style=color:#f99b15>1</span> yarn     hadoop        <span style=color:#f99b15>712</span> May <span style=color:#f99b15>12</span> 21:18 ./default_container_executor_session.sh
</span></span><span style=display:flex><span><span style=color:#f99b15>204734737</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>16</span> May <span style=color:#f99b15>12</span> 21:18 ./.default_container_executor_session.sh.crc
</span></span><span style=display:flex><span><span style=color:#f99b15>105120101</span>    <span style=color:#f99b15>4</span> drwx------   <span style=color:#f99b15>3</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__
</span></span><span style=display:flex><span><span style=color:#f99b15>105120108</span>    <span style=color:#f99b15>4</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop       <span style=color:#f99b15>3063</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__/__spark_conf__.properties
</span></span><span style=display:flex><span><span style=color:#f99b15>105120107</span>  <span style=color:#f99b15>120</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop     <span style=color:#f99b15>120306</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__/__spark_hadoop_conf__.xml
</span></span><span style=display:flex><span><span style=color:#f99b15>105120102</span>    <span style=color:#f99b15>4</span> drwx------   <span style=color:#f99b15>2</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__/__hadoop_conf__
</span></span><span style=display:flex><span><span style=color:#f99b15>105120103</span>   <span style=color:#f99b15>20</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop      <span style=color:#f99b15>19814</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__/__hadoop_conf__/yarn-site.xml
</span></span><span style=display:flex><span><span style=color:#f99b15>105120104</span>    <span style=color:#f99b15>8</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop       <span style=color:#f99b15>4282</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__/__hadoop_conf__/core-site.xml
</span></span><span style=display:flex><span><span style=color:#f99b15>105120106</span>   <span style=color:#f99b15>20</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop      <span style=color:#f99b15>19567</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__/__hadoop_conf__/hive-site.xml
</span></span><span style=display:flex><span><span style=color:#f99b15>105120105</span>   <span style=color:#f99b15>12</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop       <span style=color:#f99b15>8312</span> May <span style=color:#f99b15>12</span> 21:18 ./__spark_conf__/__hadoop_conf__/hdfs-site.xml
</span></span><span style=display:flex><span>broken symlinks<span style=color:#5bc4bf>(</span>find -L . -maxdepth <span style=color:#f99b15>5</span> -type l -ls<span style=color:#5bc4bf>)</span>:
</span></span></code></pre></div><p><code>./__spark_conf__/__hadoop_conf__/</code> 里面是外部集群配置文件，而 <code>./__spark_libs__/mySparkApp.jar</code> 是spark应用的jar，里面已经有原集群的配置文件。按 <code>CLASSPATH</code> 定义的顺序，<code>Configuration</code> 读取默认资源 <code>core-site.xml</code> 、 <code>hdfs-site.xml</code> （由<code>HdfsConfiguration</code>静态代码块加入）的时候，优先从 <code>./__spark_libs__/mySparkApp.jar</code> 读取了，而真正要用的外部集群配置，由于在 <code>CLASSPATH</code> 中位置较后，不会被加载到。</p><h3 id=解决方案>解决方案</h3><p>知道问题的原因后，根据 <code>CLASSPATH</code> 定义的顺序：</p><ul><li><code>$PWD</code> 里面的文件无法控制，跳过</li><li><code>$PWD/__spark_conf__</code> 目录里面是Driver的SparkConf内容 <code>__spark_conf__.properties</code> ，及所有hadoop相关配置整合到一起的的 <code>__spark_hadoop_conf__.xml</code> ，也是无法控制的。注意这个 <code>__spark_hadoop_conf__.xml</code> 里面虽然已经由Driver打入了外部集群的配置，但由于文件名不是 <code>hdfs-site.xml</code> ，不会被 <code>Configuration</code> 加载的。</li><li><code>$PWD/__spark_libs__/*</code> 这里面就是我们的jar包，目前里面有原集群的配置文件，这其实也违反了 <a class=link href=https://12factor.net/config target=_blank rel=noopener>12-Factor 的 Config</a> 。</li><li>中间两个忽略</li><li><code>$PWD/__spark_conf__/__hadoop_conf__</code> 就是外部集群配置文件所在</li></ul><p>那么解决方案也很简单了：</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>spark应用jar包里不要放任何 `*-site.xml` 配置文件
</span></span></code></pre></div><p>考虑到我们的Spark应用是用maven的shade插件打包的，可以配置为跳过这些xml即可：</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#5bc4bf>&lt;plugin&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#5bc4bf>&lt;groupId&gt;</span>org.apache.maven.plugins<span style=color:#5bc4bf>&lt;/groupId&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#5bc4bf>&lt;artifactId&gt;</span>maven-shade-plugin<span style=color:#5bc4bf>&lt;/artifactId&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#5bc4bf>&lt;executions&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#5bc4bf>&lt;execution&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#5bc4bf>&lt;phase&gt;</span>package<span style=color:#5bc4bf>&lt;/phase&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#5bc4bf>&lt;goals&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#5bc4bf>&lt;goal&gt;</span>shade<span style=color:#5bc4bf>&lt;/goal&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#5bc4bf>&lt;/goals&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#5bc4bf>&lt;configuration&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#5bc4bf>&lt;filters&gt;</span>
</span></span><span style=display:flex><span>                    <span style=color:#5bc4bf>&lt;filter&gt;</span>
</span></span><span style=display:flex><span>                        <span style=color:#5bc4bf>&lt;artifact&gt;</span>*:*<span style=color:#5bc4bf>&lt;/artifact&gt;</span>
</span></span><span style=display:flex><span>                        <span style=color:#5bc4bf>&lt;excludes&gt;</span>
</span></span><span style=display:flex><span>                            <span style=color:#5bc4bf>&lt;exclude&gt;</span>yarn-site.xml<span style=color:#5bc4bf>&lt;/exclude&gt;</span>
</span></span><span style=display:flex><span>                            <span style=color:#5bc4bf>&lt;exclude&gt;</span>hdfs-site.xml<span style=color:#5bc4bf>&lt;/exclude&gt;</span>
</span></span><span style=display:flex><span>                            <span style=color:#5bc4bf>&lt;exclude&gt;</span>core-site.xml<span style=color:#5bc4bf>&lt;/exclude&gt;</span>
</span></span><span style=display:flex><span>                            <span style=color:#5bc4bf>&lt;exclude&gt;</span>hbase-site.xml<span style=color:#5bc4bf>&lt;/exclude&gt;</span>
</span></span><span style=display:flex><span>                            <span style=color:#5bc4bf>&lt;exclude&gt;</span>hive-site.xml<span style=color:#5bc4bf>&lt;/exclude&gt;</span>
</span></span><span style=display:flex><span>                            <span style=color:#5bc4bf>&lt;exclude&gt;</span>kms-site.xml<span style=color:#5bc4bf>&lt;/exclude&gt;</span>
</span></span><span style=display:flex><span>                            <span style=color:#5bc4bf>&lt;exclude&gt;</span>mapred-site.xml<span style=color:#5bc4bf>&lt;/exclude&gt;</span>
</span></span><span style=display:flex><span>                        <span style=color:#5bc4bf>&lt;/excludes&gt;</span>
</span></span><span style=display:flex><span>                    <span style=color:#5bc4bf>&lt;/filter&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#5bc4bf>&lt;/filters&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#5bc4bf>&lt;/configuration&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#5bc4bf>&lt;/execution&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#5bc4bf>&lt;/executions&gt;</span>
</span></span><span style=display:flex><span><span style=color:#5bc4bf>&lt;/plugin&gt;</span>
</span></span></code></pre></div><p>重新打包、运行任务，顺利执行。</p><h2 id=spark22-与-spark24-yarn-client-模式提交任务差异>Spark2.2 与 Spark2.4 Yarn-Client 模式提交任务差异</h2><h3 id=am的classpath目录结构差异>AM的classpath、目录结构差异</h3><p>问题解决了，那么为什么Spark2.2升级Spark2.4之后就有这样的问题呢？从上面的分析，不难猜测到是AM的 <code>CLASSPATH</code> 变了。随便找一个Spark2.2提交的任务也可以看到：</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#776e71>#### launch_container.sh</span>
</span></span><span style=display:flex><span>export <span style=color:#ef6155>CLASSPATH</span><span style=color:#5bc4bf>=</span><span style=color:#48b685>&#34;</span><span style=color:#ef6155>$PWD</span><span style=color:#48b685>:</span><span style=color:#ef6155>$PWD</span><span style=color:#48b685>/__spark_conf__:</span><span style=color:#ef6155>$PWD</span><span style=color:#48b685>/__spark_libs__/*:</span><span style=color:#ef6155>$HADOOP_CONF_DIR</span><span style=color:#48b685>:</span><span style=color:#ef6155>$HADOOP_CONF_DIR</span><span style=color:#48b685>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#776e71>## 对比 Spark2.4的：</span>
</span></span><span style=display:flex><span><span style=color:#776e71>#export CLASSPATH=&#34;$PWD:$PWD/__spark_conf__:$PWD/__spark_libs__/*:$HADOOP_CONF_DIR:$HADOOP_CONF_DIR:$PWD/__spark_conf__/__hadoop_conf__&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#776e71>#### directory.info</span>
</span></span><span style=display:flex><span>find -L . -maxdepth <span style=color:#f99b15>5</span> -ls:
</span></span><span style=display:flex><span><span style=color:#f99b15>6554176</span>    <span style=color:#f99b15>4</span> drwx--x---   <span style=color:#f99b15>4</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>13</span> 11:31 .
</span></span><span style=display:flex><span><span style=color:#f99b15>6554177</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>69</span> May <span style=color:#f99b15>13</span> 11:31 ./container_tokens
</span></span><span style=display:flex><span><span style=color:#f99b15>6554182</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>16</span> May <span style=color:#f99b15>13</span> 11:31 ./.default_container_executor_session.sh.crc
</span></span><span style=display:flex><span><span style=color:#f99b15>6816116</span>    <span style=color:#f99b15>4</span> drwxr-xr-x   <span style=color:#f99b15>2</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>13</span> 11:31 ./__spark_libs__
</span></span><span style=display:flex><span><span style=color:#f99b15>32768042</span> <span style=color:#f99b15>559764</span> -r-xr-xr-x   <span style=color:#f99b15>1</span> yarn     hadoop   <span style=color:#f99b15>573191196</span> May <span style=color:#f99b15>13</span> 10:44 ./__spark_libs__/titanServEtl.jar
</span></span><span style=display:flex><span><span style=color:#f99b15>6554180</span>    <span style=color:#f99b15>4</span> -rw-r--r--   <span style=color:#f99b15>1</span> yarn     hadoop         <span style=color:#f99b15>52</span> May <span style=color:#f99b15>13</span> 11:31 ./.launch_container.sh.crc
</span></span><span style=display:flex><span><span style=color:#f99b15>31457924</span>    <span style=color:#f99b15>4</span> drwx------   <span style=color:#f99b15>2</span> yarn     hadoop       <span style=color:#f99b15>4096</span> May <span style=color:#f99b15>13</span> 11:31 ./__spark_conf__
</span></span><span style=display:flex><span><span style=color:#f99b15>31457928</span>   <span style=color:#f99b15>20</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop      <span style=color:#f99b15>19371</span> May <span style=color:#f99b15>13</span> 11:31 ./__spark_conf__/hive-site.xml
</span></span><span style=display:flex><span><span style=color:#f99b15>31457926</span>    <span style=color:#f99b15>4</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop       <span style=color:#f99b15>3064</span> May <span style=color:#f99b15>13</span> 11:31 ./__spark_conf__/core-site.xml
</span></span><span style=display:flex><span><span style=color:#f99b15>31457925</span>   <span style=color:#f99b15>20</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop      <span style=color:#f99b15>17378</span> May <span style=color:#f99b15>13</span> 11:31 ./__spark_conf__/yarn-site.xml
</span></span><span style=display:flex><span><span style=color:#f99b15>31457929</span>    <span style=color:#f99b15>4</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop       <span style=color:#f99b15>2473</span> May <span style=color:#f99b15>13</span> 11:31 ./__spark_conf__/__spark_conf__.properties
</span></span><span style=display:flex><span><span style=color:#f99b15>31457927</span>    <span style=color:#f99b15>8</span> -r-x------   <span style=color:#f99b15>1</span> yarn     hadoop       <span style=color:#f99b15>8009</span> May <span style=color:#f99b15>13</span> 11:31 ./__spark_conf__/hdfs-site.xml
</span></span></code></pre></div><p>可以看到，Spark2.4对比Spark2.2:</p><ul><li>AM 执行任务的目录：<ul><li>将 <code>*-site.xml</code> 配置文件独立放入了 <code>./__spark_conf__/__hadoop_conf__</code> 目录，而非原来的 <code>./__spark_conf__/</code> 目录</li><li>多了一个 <code>./__spark_conf__/__spark_hadoop_conf__.xml</code> 文件，存放了所有hadoop相关配置</li></ul></li><li>CLASSPATH 环境变量里将存放 <code>*-site.xml</code> 配置文件的 <code>$PWD/__spark_conf__/__hadoop_conf__</code> 目录放到了最后面。</li></ul><p>以上两个原因共同导致了本文的错误发生。</p><p>附目录对比截图：</p><p><img src=/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/spark_dir.png width=1690 height=712 srcset="/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/spark_dir_hu6d2902441b2adecf343dfaca58876801_229119_480x0_resize_box_3.png 480w, /p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/spark_dir_hu6d2902441b2adecf343dfaca58876801_229119_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=237 data-flex-basis=569px></p><h3 id=spark源码里的体现>Spark源码里的体现</h3><p>上篇博客里提到Spark的yarn-client模式是通过 <code>YarnClientSchedulerBackend</code> 处理的。<br>其 <code>start()</code> 方法会调用 <code>org.apache.spark.deploy.yarn.Client</code> 的 <code>submitApplication()</code> 方法提交Yarn AM。<br><code>submitApplication()</code> 调用 <code>createContainerLaunchContext</code> 构造ContainerLaunchContext对应的上下文，构建的启动Yarn AM的任务命令cmds，里面比较重要的有两步:</p><ol><li>调用 <code>setupLaunchEnv()</code> 构造环境变量，其中我们关心的 <code>CLASSPATH</code> 是在 <code>populateClasspath()</code> 方法里处理的；</li><li>调用 <code>prepareLocalResources()</code> 准备Yarn AM需要的一些资源，包括调用 <code>createConfArchive()</code> 创建 <code>__spark_conf__.zip</code> ，里面解压出来就是上面所讨论的AM 目录结构里面的 <code>./__spark_conf__/</code> 目录</li></ol><h4 id=populateclasspath>populateClasspath()</h4><p>对比两个版本的 <code>populateClasspath()</code> 方法，注意差异在最后：</p><p><img src=/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/populateClasspath.png width=3624 height=2248 srcset="/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/populateClasspath_hu8dc1913df6b01084e2ef7ab5c80946cd_360458_480x0_resize_box_3.png 480w, /p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/populateClasspath_hu8dc1913df6b01084e2ef7ab5c80946cd_360458_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=161 data-flex-basis=386px></p><p>参考注释：</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#776e71>// Add the localized Hadoop config at the end of the classpath, in case it contains other</span>
</span></span><span style=display:flex><span><span style=color:#776e71>// files (such as configuration files for different services) that are not part of the</span>
</span></span><span style=display:flex><span><span style=color:#776e71>// YARN cluster&#39;s config.</span>
</span></span></code></pre></div><p>是为了防止将其他非Yarn集群配置的文件也引入了。</p><h4 id=createconfarchive>createConfArchive()</h4><p>这个代码略多，挑一些重点的讲讲，以Spark2.4为基准。</p><p><a class=link href=https://issues.apache.org/jira/browse/SPARK-23630 target=_blank rel=noopener>SPARK-23630</a> 增加了一个用于测试的环境变量 <code>SPARK_TEST_HADOOP_CONF_DIR</code> ，该环境变量指定的目录里面的配置文件也会被打进去 <code>__spark_conf__.zip</code> 。</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#776e71>// SPARK-23630: during testing, Spark scripts filter out hadoop conf dirs so that user&#39;s
</span></span></span><span style=display:flex><span><span style=color:#776e71>// environments do not interfere with tests. This allows a special env variable during
</span></span></span><span style=display:flex><span><span style=color:#776e71>// tests so that custom conf dirs can be used by unit tests.
</span></span></span><span style=display:flex><span><span style=color:#776e71></span><span style=color:#815ba4>val</span> confDirs <span style=color:#815ba4>=</span> <span style=color:#fec418>Seq</span><span style=color:#5bc4bf>(</span><span style=color:#48b685>&#34;HADOOP_CONF_DIR&#34;</span><span style=color:#5bc4bf>,</span> <span style=color:#48b685>&#34;YARN_CONF_DIR&#34;</span><span style=color:#5bc4bf>)</span> <span style=color:#5bc4bf>++</span>
</span></span><span style=display:flex><span>    <span style=color:#5bc4bf>(</span><span style=color:#815ba4>if</span> <span style=color:#5bc4bf>(</span><span style=color:#fec418>Utils</span><span style=color:#5bc4bf>.</span>isTesting<span style=color:#5bc4bf>)</span> <span style=color:#fec418>Seq</span><span style=color:#5bc4bf>(</span><span style=color:#48b685>&#34;SPARK_TEST_HADOOP_CONF_DIR&#34;</span><span style=color:#5bc4bf>)</span> <span style=color:#815ba4>else</span> <span style=color:#fec418>Nil</span><span style=color:#5bc4bf>)</span>
</span></span></code></pre></div><p>hadoop配置文件独立出来，放在 <code>__hadoop_conf__</code> 目录。</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#776e71>// Save the Hadoop config files under a separate directory in the archive. This directory
</span></span></span><span style=display:flex><span><span style=color:#776e71>// is appended to the classpath so that the cluster-provided configuration takes precedence.
</span></span></span><span style=display:flex><span><span style=color:#776e71></span>confStream<span style=color:#5bc4bf>.</span>putNextEntry<span style=color:#5bc4bf>(</span><span style=color:#815ba4>new</span> <span style=color:#fec418>ZipEntry</span><span style=color:#5bc4bf>(</span><span style=color:#48b685>s&#34;</span><span style=color:#f99b15>$LOCALIZED_HADOOP_CONF_DIR</span><span style=color:#48b685>/&#34;</span><span style=color:#5bc4bf>))</span>
</span></span><span style=display:flex><span>confStream<span style=color:#5bc4bf>.</span>closeEntry<span style=color:#5bc4bf>()</span>
</span></span><span style=display:flex><span>hadoopConfFiles<span style=color:#5bc4bf>.</span>foreach <span style=color:#5bc4bf>{</span> <span style=color:#815ba4>case</span> <span style=color:#5bc4bf>(</span>name<span style=color:#5bc4bf>,</span> file<span style=color:#5bc4bf>)</span> <span style=color:#815ba4>=&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#815ba4>if</span> <span style=color:#5bc4bf>(</span>file<span style=color:#5bc4bf>.</span>canRead<span style=color:#5bc4bf>())</span> <span style=color:#5bc4bf>{</span>
</span></span><span style=display:flex><span>        confStream<span style=color:#5bc4bf>.</span>putNextEntry<span style=color:#5bc4bf>(</span><span style=color:#815ba4>new</span> <span style=color:#fec418>ZipEntry</span><span style=color:#5bc4bf>(</span><span style=color:#48b685>s&#34;</span><span style=color:#f99b15>$LOCALIZED_HADOOP_CONF_DIR</span><span style=color:#48b685>/</span><span style=color:#f99b15>$name</span><span style=color:#48b685>&#34;</span><span style=color:#5bc4bf>))</span>
</span></span><span style=display:flex><span>        <span style=color:#fec418>Files</span><span style=color:#5bc4bf>.</span>copy<span style=color:#5bc4bf>(</span>file<span style=color:#5bc4bf>,</span> confStream<span style=color:#5bc4bf>)</span>
</span></span><span style=display:flex><span>        confStream<span style=color:#5bc4bf>.</span>closeEntry<span style=color:#5bc4bf>()</span>
</span></span><span style=display:flex><span>    <span style=color:#5bc4bf>}</span>
</span></span><span style=display:flex><span><span style=color:#5bc4bf>}</span>
</span></span></code></pre></div><p>增加了一个 <code>__spark_hadoop_conf__.xml</code> 存放所有hadoop配置。</p><div class=highlight><pre tabindex=0 style=color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#776e71>//Client 里面的代码
</span></span></span><span style=display:flex><span><span style=color:#776e71></span><span style=color:#815ba4>private</span> <span style=color:#815ba4>val</span> hadoopConf <span style=color:#815ba4>=</span> <span style=color:#815ba4>new</span> <span style=color:#fec418>YarnConfiguration</span><span style=color:#5bc4bf>(</span><span style=color:#fec418>SparkHadoopUtil</span><span style=color:#5bc4bf>.</span>newConfiguration<span style=color:#5bc4bf>(</span>sparkConf<span style=color:#5bc4bf>))</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#776e71>//createConfArchive() 里面的代码
</span></span></span><span style=display:flex><span><span style=color:#776e71>// Save the YARN configuration into a separate file that will be overlayed on top of the
</span></span></span><span style=display:flex><span><span style=color:#776e71>// cluster&#39;s Hadoop conf.
</span></span></span><span style=display:flex><span><span style=color:#776e71></span>confStream<span style=color:#5bc4bf>.</span>putNextEntry<span style=color:#5bc4bf>(</span><span style=color:#815ba4>new</span> <span style=color:#fec418>ZipEntry</span><span style=color:#5bc4bf>(</span><span style=color:#fec418>SparkHadoopUtil</span><span style=color:#5bc4bf>.</span><span style=color:#fec418>SPARK_HADOOP_CONF_FILE</span><span style=color:#5bc4bf>))</span>
</span></span><span style=display:flex><span>hadoopConf<span style=color:#5bc4bf>.</span>writeXml<span style=color:#5bc4bf>(</span>confStream<span style=color:#5bc4bf>)</span>
</span></span><span style=display:flex><span>confStream<span style=color:#5bc4bf>.</span>closeEntry<span style=color:#5bc4bf>()</span>
</span></span></code></pre></div></section><footer class=article-footer><section class=article-tags><a href=/tags/Spark/>Spark</a>
<a href=/tags/Hadoop/>Hadoop</a>
<a href=/tags/Yarn/>Yarn</a>
<a href=/tags/%E8%B7%A8%E9%9B%86%E7%BE%A4/>跨集群</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under Apache License 2.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1/><div class=article-image><img src=/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1/93990522.6ffc646414c62cc1e740b2f5bc0f7b49_hu6aa0acda77cb3b4cc5d51f0a61452bcb_184592_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post 跨Yarn集群提交spark任务" data-hash="md5-b/xkZBTGLMHnQLL1vA97SQ=="></div><div class=article-details><h2 class=article-title>跨Yarn集群提交spark任务</h2></div></a></article><article class=has-image><a href=/p/%E4%BF%AE%E5%A4%8DElasticsearch-hadoop%E6%9F%A5%E8%AF%A2%E6%9D%A1%E4%BB%B6%E5%B8%A6emoji%E6%97%B6%E7%9A%84JsonGenerationException/><div class=article-image><img src=/p/%E4%BF%AE%E5%A4%8DElasticsearch-hadoop%E6%9F%A5%E8%AF%A2%E6%9D%A1%E4%BB%B6%E5%B8%A6emoji%E6%97%B6%E7%9A%84JsonGenerationException/bg1.9ed074639915eb593a7d4b504a93b1e3_hu45c6181425d2bec34f45ee6e4ec4a6e2_647451_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post 修复Elasticsearch-hadoop查询条件带emoji时的JsonGenerationException" data-hash="md5-ntB0Y5kV61k6fUtQSpOx4w=="></div><div class=article-details><h2 class=article-title>修复Elasticsearch-hadoop查询条件带emoji时的JsonGenerationException</h2></div></a></article><article class=has-image><a href=/p/%E4%BF%AE%E5%A4%8DElasticsearch-hadoop%E8%AF%BB%E5%8F%96%E7%89%B9%E6%AE%8A%E6%95%B0%E5%AD%97%E5%8F%96%E5%80%BC%E6%97%B6%E7%9A%84NumberFormatException/><div class=article-image><img src=/p/%E4%BF%AE%E5%A4%8DElasticsearch-hadoop%E8%AF%BB%E5%8F%96%E7%89%B9%E6%AE%8A%E6%95%B0%E5%AD%97%E5%8F%96%E5%80%BC%E6%97%B6%E7%9A%84NumberFormatException/bg2.1cec89e82f674ddee278bdb45efae3e9_hu581b7b12baca6a4e8f95bd7dff860ba9_184982_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post 修复Elasticsearch-hadoop读取特殊数字取值时的NumberFormatException" data-hash="md5-HOyJ6C9nTd7ieL20Xvrj6Q=="></div><div class=article-details><h2 class=article-title>修复Elasticsearch-hadoop读取特殊数字取值时的NumberFormatException</h2></div></a></article><article class=has-image><a href=/p/Spark%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDhive%E9%85%8D%E7%BD%AE%E7%9A%84%E6%96%B9%E6%A1%88/><div class=article-image><img src=/p/Spark%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDhive%E9%85%8D%E7%BD%AE%E7%9A%84%E6%96%B9%E6%A1%88/bg3.21f41c6e14fb98426d8d634cdcff4e48_hu04adce3b52cc8e582e668512c3886fe4_174126_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post Spark动态加载hive配置的方案" data-hash="md5-IfQcbhT7mEJtjWNM3P9OSA=="></div><div class=article-details><h2 class=article-title>Spark动态加载hive配置的方案</h2></div></a></article><article class=has-image><a href=/p/Spark%E5%86%99Mongodb%E7%9A%84%E5%B0%8F%E5%9D%91/><div class=article-image><img src=/p/Spark%E5%86%99Mongodb%E7%9A%84%E5%B0%8F%E5%9D%91/zelda.232f7f0a17ebcc514cf6da9d6a07c114_hu62caf65ed048351c8a298072e6e03294_171791_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post Spark写Mongodb的小坑" data-hash="md5-Iy9/ChfrzFFM9tqdagfBFA=="></div><div class=article-details><h2 class=article-title>Spark写Mongodb的小坑</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//leibnizhu.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2016 -
2024 Heaven's Door</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.13.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#背景>背景</a></li><li><a href=#问题原因分析及解决方案>问题、原因分析、及解决方案</a><ol><li><a href=#spark24中的报错>Spark2.4中的报错</a></li><li><a href=#直接原因分析>直接原因分析</a></li><li><a href=#解决方案>解决方案</a></li></ol></li><li><a href=#spark22-与-spark24-yarn-client-模式提交任务差异>Spark2.2 与 Spark2.4 Yarn-Client 模式提交任务差异</a><ol><li><a href=#am的classpath目录结构差异>AM的classpath、目录结构差异</a></li><li><a href=#spark源码里的体现>Spark源码里的体现</a><ol><li><a href=#populateclasspath>populateClasspath()</a></li><li><a href=#createconfarchive>createConfArchive()</a></li></ol></li></ol></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>