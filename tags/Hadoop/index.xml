<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hadoop on Heaven's Door</title><link>https://leibnizhu.github.io/tags/Hadoop/</link><description>Recent content in Hadoop on Heaven's Door</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 14 May 2022 20:33:58 +0800</lastBuildDate><atom:link href="https://leibnizhu.github.io/tags/Hadoop/index.xml" rel="self" type="application/rss+xml"/><item><title>跨Yarn集群提交spark任务——之Spark2.4坑</title><link>https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/</link><pubDate>Sat, 14 May 2022 20:33:58 +0800</pubDate><guid>https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/</guid><description>&lt;img src="https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/blackcat.jpeg" alt="Featured image of post 跨Yarn集群提交spark任务——之Spark2.4坑" />&lt;h2 id="背景">背景&lt;/h2>
&lt;p>去年写过一篇 &lt;a class="link" href="https://leibnizhu.github.io/2021/12/04/%e8%b7%a8Yarn%e9%9b%86%e7%be%a4%e6%8f%90%e4%ba%a4spark%e4%bb%bb%e5%8a%a1/" >跨Yarn集群提交spark任务&lt;/a> ，是在Spark2.2基础上做的动态提交外部Yarn集群。这里“动态”指不事先将 &lt;code>*-site.xml&lt;/code> 打入jar包，而是执行任务时根据配置按需提交到对应集群；而“外部”集群是相对jar包中（如果已有）的 &lt;code>*-site.xml&lt;/code> 对应的集群以外的集群，也是在“动态”提交的context中定义的，可以理解为提交到任意网络互通的集群。&lt;/p>
&lt;p>简单回顾下，主要做了两件事情：&lt;/p>
&lt;ol>
&lt;li>创建SparkContext前，将外部集群的 &lt;code>*-site.xml&lt;/code> 放入classpath，如 &lt;code>$PWD&lt;/code> 。&lt;/li>
&lt;li>创建SparkContext前，&lt;code>HADOOP_CONF_DIR&lt;/code> 和 &lt;code>YARN_CONF_DIR&lt;/code> 环境变量改为外部集群 &lt;code>*-site.xml&lt;/code> 配置文件所在位置；由于启动java程序后不能直接修改环境变量，在实现上使用了黑魔法。&lt;/li>
&lt;/ol>
&lt;p>时隔半年终于重拾博客，显然又被坑了，没错，之前的方法在Spark2.4里行不通了。&lt;/p>
&lt;h2 id="问题原因分析及解决方案">问题、原因分析、及解决方案&lt;/h2>
&lt;h3 id="spark24中的报错">Spark2.4中的报错&lt;/h3>
&lt;p>在原来代码基础上，升级Spark为2.4.8，执行提交到外部集群的任务，提交到Yarn的AM报错如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-fallback" data-lang="fallback">&lt;span style="display:flex;">&lt;span>Container id: container_e36_1650338235135_41710_02_000001
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Exit code: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Container exited with a non-zero exit code 1. Error file: prelaunch.err.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Last 4096 bytes of prelaunch.err :
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Last 4096 bytes of stderr :
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Exception in thread &amp;#34;main&amp;#34; java.lang.IllegalArgumentException: java.net.UnknownHostException: channel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:665)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:601)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2619)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2653)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2635)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8$$anonfun$apply$3.apply(ApplicationMaster.scala:219)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8$$anonfun$apply$3.apply(ApplicationMaster.scala:217)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at scala.Option.foreach(Option.scala:257)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8.apply(ApplicationMaster.scala:217)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$8.apply(ApplicationMaster.scala:182)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:780)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at java.security.AccessController.doPrivileged(Native Method)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at javax.security.auth.Subject.doAs(Subject.java:422)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster.doAsUser(ApplicationMaster.scala:779)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster.&amp;lt;init&amp;gt;(ApplicationMaster.scala:182)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:803)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:834)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> at org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Caused by: java.net.UnknownHostException: xxx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ... 25 more
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中 &lt;code>xxx&lt;/code> 是外部集群的集群名（&lt;code>dfs.nameservices&lt;/code> 配置）。&lt;/p>
&lt;h3 id="直接原因分析">直接原因分析&lt;/h3>
&lt;p>仔细观察异常的调用栈，调用到了 &lt;code>NameNodeProxies.createNonHAProxy&lt;/code> ，而我们的集群是HA的，显然是读取到的配置不对了。&lt;/p>
&lt;p>看到这个类，阅读过hadoop源码的应该都知道，这是创建 &lt;code>DFSClient&lt;/code> 的时候，会先读取 &lt;code>dfs.client.failover.proxy.provider.{hdfs路径对应host}&lt;/code> 配置（取值是一个 &lt;code>FailoverProxyProvider&lt;/code> 具体实现的全限定类名），反射出Class对象并实例化，然后创建对应的HAProxy；而如果配置为空，则认为NameNode没有开启HA，直接将hdfs路径当作普通host来进行读取，如果实际上这个host是一个HA的nameservices名，不存在这个host，则会报上面的错误。&lt;/p>
&lt;p>所以可以确定，是AM读取不到正确的hdfs配置导致的。那么是为什么呢？&lt;/p>
&lt;p>仔细观察AM的日志，&lt;code>launch_container.sh&lt;/code> 里面：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#………………&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export &lt;span style="color:#ef6155">HADOOP_YARN_HOME&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#f99b15">${&lt;/span>&lt;span style="color:#ef6155">HADOOP_YARN_HOME&lt;/span>&lt;span style="color:#815ba4">:-&lt;/span>&lt;span style="color:#48b685">&amp;#34;/usr/hdp/2.6.5.0-292/hadoop-yarn&amp;#34;&lt;/span>&lt;span style="color:#f99b15">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export &lt;span style="color:#ef6155">CLASSPATH&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;&lt;/span>&lt;span style="color:#ef6155">$PWD&lt;/span>&lt;span style="color:#48b685">:&lt;/span>&lt;span style="color:#ef6155">$PWD&lt;/span>&lt;span style="color:#48b685">/__spark_conf__:&lt;/span>&lt;span style="color:#ef6155">$PWD&lt;/span>&lt;span style="color:#48b685">/__spark_libs__/*:&lt;/span>&lt;span style="color:#ef6155">$HADOOP_CONF_DIR&lt;/span>&lt;span style="color:#48b685">:&lt;/span>&lt;span style="color:#ef6155">$HADOOP_CONF_DIR&lt;/span>&lt;span style="color:#48b685">:&lt;/span>&lt;span style="color:#ef6155">$PWD&lt;/span>&lt;span style="color:#48b685">/__spark_conf__/__hadoop_conf__&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export &lt;span style="color:#ef6155">SPARK_CONF_DIR&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;/opt/package/spark-2.4.8-bin-hadoop2.6/conf&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#………………&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>同时注意到 directory.info 记录的目录结构：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>ls -l:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total &lt;span style="color:#f99b15">32&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">71&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 container_tokens
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-rwx------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">712&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 default_container_executor_session.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-rwx------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">766&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 default_container_executor.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>-rwx------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">5787&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 launch_container.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lrwxrwxrwx &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">80&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 __spark_conf__ -&amp;gt; /path/to/filecache/29549/__spark_conf__.zip
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>drwxr-xr-x &lt;span style="color:#f99b15">2&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 __spark_libs__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>drwx--x--- &lt;span style="color:#f99b15">2&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 tmp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>find -L . -maxdepth &lt;span style="color:#f99b15">5&lt;/span> -ls:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734730&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwx--x--- &lt;span style="color:#f99b15">4&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 .
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734738&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rwx------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">766&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./default_container_executor.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734734&lt;/span> &lt;span style="color:#f99b15">8&lt;/span> -rwx------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">5787&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./launch_container.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734733&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">12&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./.container_tokens.crc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734741&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwxr-xr-x &lt;span style="color:#f99b15">2&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_libs__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105382561&lt;/span> &lt;span style="color:#f99b15">555832&lt;/span> -r-xr-xr-x &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">569170427&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_libs__/mySparkApp.jar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734731&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwx--x--- &lt;span style="color:#f99b15">2&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./tmp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734735&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">56&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./.launch_container.sh.crc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734739&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">16&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./.default_container_executor.sh.crc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734732&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">71&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./container_tokens
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734736&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rwx------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">712&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./default_container_executor_session.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">204734737&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">16&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./.default_container_executor_session.sh.crc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120101&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwx------ &lt;span style="color:#f99b15">3&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120108&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">3063&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__/__spark_conf__.properties
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120107&lt;/span> &lt;span style="color:#f99b15">120&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">120306&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__/__spark_hadoop_conf__.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120102&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwx------ &lt;span style="color:#f99b15">2&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__/__hadoop_conf__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120103&lt;/span> &lt;span style="color:#f99b15">20&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">19814&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__/__hadoop_conf__/yarn-site.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120104&lt;/span> &lt;span style="color:#f99b15">8&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4282&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__/__hadoop_conf__/core-site.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120106&lt;/span> &lt;span style="color:#f99b15">20&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">19567&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__/__hadoop_conf__/hive-site.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">105120105&lt;/span> &lt;span style="color:#f99b15">12&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">8312&lt;/span> May &lt;span style="color:#f99b15">12&lt;/span> 21:18 ./__spark_conf__/__hadoop_conf__/hdfs-site.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>broken symlinks&lt;span style="color:#5bc4bf">(&lt;/span>find -L . -maxdepth &lt;span style="color:#f99b15">5&lt;/span> -type l -ls&lt;span style="color:#5bc4bf">)&lt;/span>:
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>./__spark_conf__/__hadoop_conf__/&lt;/code> 里面是外部集群配置文件，而 &lt;code>./__spark_libs__/mySparkApp.jar&lt;/code> 是spark应用的jar，里面已经有原集群的配置文件。按 &lt;code>CLASSPATH&lt;/code> 定义的顺序，&lt;code>Configuration&lt;/code> 读取默认资源 &lt;code>core-site.xml&lt;/code> 、 &lt;code>hdfs-site.xml&lt;/code> （由&lt;code>HdfsConfiguration&lt;/code>静态代码块加入）的时候，优先从 &lt;code>./__spark_libs__/mySparkApp.jar&lt;/code> 读取了，而真正要用的外部集群配置，由于在 &lt;code>CLASSPATH&lt;/code> 中位置较后，不会被加载到。&lt;/p>
&lt;h3 id="解决方案">解决方案&lt;/h3>
&lt;p>知道问题的原因后，根据 &lt;code>CLASSPATH&lt;/code> 定义的顺序：&lt;/p>
&lt;ul>
&lt;li>&lt;code>$PWD&lt;/code> 里面的文件无法控制，跳过&lt;/li>
&lt;li>&lt;code>$PWD/__spark_conf__&lt;/code> 目录里面是Driver的SparkConf内容 &lt;code>__spark_conf__.properties&lt;/code> ，及所有hadoop相关配置整合到一起的的 &lt;code>__spark_hadoop_conf__.xml&lt;/code> ，也是无法控制的。注意这个 &lt;code>__spark_hadoop_conf__.xml&lt;/code> 里面虽然已经由Driver打入了外部集群的配置，但由于文件名不是 &lt;code>hdfs-site.xml&lt;/code> ，不会被 &lt;code>Configuration&lt;/code> 加载的。&lt;/li>
&lt;li>&lt;code>$PWD/__spark_libs__/*&lt;/code> 这里面就是我们的jar包，目前里面有原集群的配置文件，这其实也违反了 &lt;a class="link" href="https://12factor.net/config" target="_blank" rel="noopener"
>12-Factor 的 Config&lt;/a> 。&lt;/li>
&lt;li>中间两个忽略&lt;/li>
&lt;li>&lt;code>$PWD/__spark_conf__/__hadoop_conf__&lt;/code> 就是外部集群配置文件所在&lt;/li>
&lt;/ul>
&lt;p>那么解决方案也很简单了：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-fallback" data-lang="fallback">&lt;span style="display:flex;">&lt;span>spark应用jar包里不要放任何 `*-site.xml` 配置文件
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>考虑到我们的Spark应用是用maven的shade插件打包的，可以配置为跳过这些xml即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">&amp;lt;plugin&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>org.apache.maven.plugins&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>maven-shade-plugin&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;executions&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;execution&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;phase&amp;gt;&lt;/span>package&lt;span style="color:#5bc4bf">&amp;lt;/phase&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;goals&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;goal&amp;gt;&lt;/span>shade&lt;span style="color:#5bc4bf">&amp;lt;/goal&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/goals&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;configuration&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;filters&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;filter&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifact&amp;gt;&lt;/span>*:*&lt;span style="color:#5bc4bf">&amp;lt;/artifact&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;excludes&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclude&amp;gt;&lt;/span>yarn-site.xml&lt;span style="color:#5bc4bf">&amp;lt;/exclude&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclude&amp;gt;&lt;/span>hdfs-site.xml&lt;span style="color:#5bc4bf">&amp;lt;/exclude&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclude&amp;gt;&lt;/span>core-site.xml&lt;span style="color:#5bc4bf">&amp;lt;/exclude&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclude&amp;gt;&lt;/span>hbase-site.xml&lt;span style="color:#5bc4bf">&amp;lt;/exclude&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclude&amp;gt;&lt;/span>hive-site.xml&lt;span style="color:#5bc4bf">&amp;lt;/exclude&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclude&amp;gt;&lt;/span>kms-site.xml&lt;span style="color:#5bc4bf">&amp;lt;/exclude&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclude&amp;gt;&lt;/span>mapred-site.xml&lt;span style="color:#5bc4bf">&amp;lt;/exclude&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/excludes&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/filter&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/filters&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/configuration&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/execution&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/executions&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">&amp;lt;/plugin&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>重新打包、运行任务，顺利执行。&lt;/p>
&lt;h2 id="spark22-与-spark24-yarn-client-模式提交任务差异">Spark2.2 与 Spark2.4 Yarn-Client 模式提交任务差异&lt;/h2>
&lt;h3 id="am的classpath目录结构差异">AM的classpath、目录结构差异&lt;/h3>
&lt;p>问题解决了，那么为什么Spark2.2升级Spark2.4之后就有这样的问题呢？从上面的分析，不难猜测到是AM的 &lt;code>CLASSPATH&lt;/code> 变了。随便找一个Spark2.2提交的任务也可以看到：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#### launch_container.sh&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export &lt;span style="color:#ef6155">CLASSPATH&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;&lt;/span>&lt;span style="color:#ef6155">$PWD&lt;/span>&lt;span style="color:#48b685">:&lt;/span>&lt;span style="color:#ef6155">$PWD&lt;/span>&lt;span style="color:#48b685">/__spark_conf__:&lt;/span>&lt;span style="color:#ef6155">$PWD&lt;/span>&lt;span style="color:#48b685">/__spark_libs__/*:&lt;/span>&lt;span style="color:#ef6155">$HADOOP_CONF_DIR&lt;/span>&lt;span style="color:#48b685">:&lt;/span>&lt;span style="color:#ef6155">$HADOOP_CONF_DIR&lt;/span>&lt;span style="color:#48b685">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">## 对比 Spark2.4的：&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#export CLASSPATH=&amp;#34;$PWD:$PWD/__spark_conf__:$PWD/__spark_libs__/*:$HADOOP_CONF_DIR:$HADOOP_CONF_DIR:$PWD/__spark_conf__/__hadoop_conf__&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#### directory.info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>find -L . -maxdepth &lt;span style="color:#f99b15">5&lt;/span> -ls:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">6554176&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwx--x--- &lt;span style="color:#f99b15">4&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 .
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">6554177&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">69&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./container_tokens
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">6554182&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">16&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./.default_container_executor_session.sh.crc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">6816116&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwxr-xr-x &lt;span style="color:#f99b15">2&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./__spark_libs__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">32768042&lt;/span> &lt;span style="color:#f99b15">559764&lt;/span> -r-xr-xr-x &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">573191196&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 10:44 ./__spark_libs__/titanServEtl.jar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">6554180&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -rw-r--r-- &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">52&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./.launch_container.sh.crc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">31457924&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> drwx------ &lt;span style="color:#f99b15">2&lt;/span> yarn hadoop &lt;span style="color:#f99b15">4096&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./__spark_conf__
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">31457928&lt;/span> &lt;span style="color:#f99b15">20&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">19371&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./__spark_conf__/hive-site.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">31457926&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">3064&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./__spark_conf__/core-site.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">31457925&lt;/span> &lt;span style="color:#f99b15">20&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">17378&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./__spark_conf__/yarn-site.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">31457929&lt;/span> &lt;span style="color:#f99b15">4&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">2473&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./__spark_conf__/__spark_conf__.properties
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f99b15">31457927&lt;/span> &lt;span style="color:#f99b15">8&lt;/span> -r-x------ &lt;span style="color:#f99b15">1&lt;/span> yarn hadoop &lt;span style="color:#f99b15">8009&lt;/span> May &lt;span style="color:#f99b15">13&lt;/span> 11:31 ./__spark_conf__/hdfs-site.xml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到，Spark2.4对比Spark2.2:&lt;/p>
&lt;ul>
&lt;li>AM 执行任务的目录：
&lt;ul>
&lt;li>将 &lt;code>*-site.xml&lt;/code> 配置文件独立放入了 &lt;code>./__spark_conf__/__hadoop_conf__&lt;/code> 目录，而非原来的 &lt;code>./__spark_conf__/&lt;/code> 目录&lt;/li>
&lt;li>多了一个 &lt;code>./__spark_conf__/__spark_hadoop_conf__.xml&lt;/code> 文件，存放了所有hadoop相关配置&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>CLASSPATH 环境变量里将存放 &lt;code>*-site.xml&lt;/code> 配置文件的 &lt;code>$PWD/__spark_conf__/__hadoop_conf__&lt;/code> 目录放到了最后面。&lt;/li>
&lt;/ul>
&lt;p>以上两个原因共同导致了本文的错误发生。&lt;/p>
&lt;p>附目录对比截图：&lt;/p>
&lt;p>&lt;img src="https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/spark_dir.png"
width="1690"
height="712"
srcset="https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/spark_dir_hu6d2902441b2adecf343dfaca58876801_229119_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/spark_dir_hu6d2902441b2adecf343dfaca58876801_229119_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="237"
data-flex-basis="569px"
>&lt;/p>
&lt;h3 id="spark源码里的体现">Spark源码里的体现&lt;/h3>
&lt;p>上篇博客里提到Spark的yarn-client模式是通过 &lt;code>YarnClientSchedulerBackend&lt;/code> 处理的。&lt;br>
其 &lt;code>start()&lt;/code> 方法会调用 &lt;code>org.apache.spark.deploy.yarn.Client&lt;/code> 的 &lt;code>submitApplication()&lt;/code> 方法提交Yarn AM。&lt;br>
&lt;code>submitApplication()&lt;/code> 调用 &lt;code>createContainerLaunchContext&lt;/code> 构造ContainerLaunchContext对应的上下文，构建的启动Yarn AM的任务命令cmds，里面比较重要的有两步:&lt;/p>
&lt;ol>
&lt;li>调用 &lt;code>setupLaunchEnv()&lt;/code> 构造环境变量，其中我们关心的 &lt;code>CLASSPATH&lt;/code> 是在 &lt;code>populateClasspath()&lt;/code> 方法里处理的；&lt;/li>
&lt;li>调用 &lt;code>prepareLocalResources()&lt;/code> 准备Yarn AM需要的一些资源，包括调用 &lt;code>createConfArchive()&lt;/code> 创建 &lt;code>__spark_conf__.zip&lt;/code> ，里面解压出来就是上面所讨论的AM 目录结构里面的 &lt;code>./__spark_conf__/&lt;/code> 目录&lt;/li>
&lt;/ol>
&lt;h4 id="populateclasspath">populateClasspath()&lt;/h4>
&lt;p>对比两个版本的 &lt;code>populateClasspath()&lt;/code> 方法，注意差异在最后：&lt;/p>
&lt;p>&lt;img src="https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/populateClasspath.png"
width="3624"
height="2248"
srcset="https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/populateClasspath_hu8dc1913df6b01084e2ef7ab5c80946cd_360458_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1%E4%B9%8BSpark2.4%E5%9D%91/populateClasspath_hu8dc1913df6b01084e2ef7ab5c80946cd_360458_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="161"
data-flex-basis="386px"
>&lt;/p>
&lt;p>参考注释：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// Add the localized Hadoop config at the end of the classpath, in case it contains other
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// files (such as configuration files for different services) that are not part of the
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// YARN cluster&amp;#39;s config.
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>是为了防止将其他非Yarn集群配置的文件也引入了。&lt;/p>
&lt;h4 id="createconfarchive">createConfArchive()&lt;/h4>
&lt;p>这个代码略多，挑一些重点的讲讲，以Spark2.4为基准。&lt;/p>
&lt;p>&lt;a class="link" href="https://issues.apache.org/jira/browse/SPARK-23630" target="_blank" rel="noopener"
>SPARK-23630&lt;/a> 增加了一个用于测试的环境变量 &lt;code>SPARK_TEST_HADOOP_CONF_DIR&lt;/code> ，该环境变量指定的目录里面的配置文件也会被打进去 &lt;code>__spark_conf__.zip&lt;/code> 。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// SPARK-23630: during testing, Spark scripts filter out hadoop conf dirs so that user&amp;#39;s
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// environments do not interfere with tests. This allows a special env variable during
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// tests so that custom conf dirs can be used by unit tests.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>&lt;span style="color:#815ba4">val&lt;/span> confDirs &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">Seq&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;HADOOP_CONF_DIR&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;YARN_CONF_DIR&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">++&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">if&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">Utils&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>isTesting&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#fec418">Seq&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;SPARK_TEST_HADOOP_CONF_DIR&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#815ba4">else&lt;/span> &lt;span style="color:#fec418">Nil&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>hadoop配置文件独立出来，放在 &lt;code>__hadoop_conf__&lt;/code> 目录。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// Save the Hadoop config files under a separate directory in the archive. This directory
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// is appended to the classpath so that the cluster-provided configuration takes precedence.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>confStream&lt;span style="color:#5bc4bf">.&lt;/span>putNextEntry&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ZipEntry&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">s&amp;#34;&lt;/span>&lt;span style="color:#f99b15">$LOCALIZED_HADOOP_CONF_DIR&lt;/span>&lt;span style="color:#48b685">/&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>confStream&lt;span style="color:#5bc4bf">.&lt;/span>closeEntry&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hadoopConfFiles&lt;span style="color:#5bc4bf">.&lt;/span>foreach &lt;span style="color:#5bc4bf">{&lt;/span> &lt;span style="color:#815ba4">case&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>name&lt;span style="color:#5bc4bf">,&lt;/span> file&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#815ba4">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>file&lt;span style="color:#5bc4bf">.&lt;/span>canRead&lt;span style="color:#5bc4bf">())&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> confStream&lt;span style="color:#5bc4bf">.&lt;/span>putNextEntry&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ZipEntry&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">s&amp;#34;&lt;/span>&lt;span style="color:#f99b15">$LOCALIZED_HADOOP_CONF_DIR&lt;/span>&lt;span style="color:#48b685">/&lt;/span>&lt;span style="color:#f99b15">$name&lt;/span>&lt;span style="color:#48b685">&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">Files&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>copy&lt;span style="color:#5bc4bf">(&lt;/span>file&lt;span style="color:#5bc4bf">,&lt;/span> confStream&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> confStream&lt;span style="color:#5bc4bf">.&lt;/span>closeEntry&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>增加了一个 &lt;code>__spark_hadoop_conf__.xml&lt;/code> 存放所有hadoop配置。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">//Client 里面的代码
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>&lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> hadoopConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">YarnConfiguration&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">SparkHadoopUtil&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>newConfiguration&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">//createConfArchive() 里面的代码
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// Save the YARN configuration into a separate file that will be overlayed on top of the
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// cluster&amp;#39;s Hadoop conf.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>confStream&lt;span style="color:#5bc4bf">.&lt;/span>putNextEntry&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ZipEntry&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">SparkHadoopUtil&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#fec418">SPARK_HADOOP_CONF_FILE&lt;/span>&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hadoopConf&lt;span style="color:#5bc4bf">.&lt;/span>writeXml&lt;span style="color:#5bc4bf">(&lt;/span>confStream&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>confStream&lt;span style="color:#5bc4bf">.&lt;/span>closeEntry&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>跨Yarn集群提交spark任务</title><link>https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1/</link><pubDate>Sat, 04 Dec 2021 18:17:55 +0800</pubDate><guid>https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1/</guid><description>&lt;img src="https://leibnizhu.github.io/p/%E8%B7%A8Yarn%E9%9B%86%E7%BE%A4%E6%8F%90%E4%BA%A4spark%E4%BB%BB%E5%8A%A1/93990522.jpg" alt="Featured image of post 跨Yarn集群提交spark任务" />&lt;h2 id="背景">背景&lt;/h2>
&lt;p>之前写过一篇 &lt;a class="link" href="https://leibnizhu.github.io/2020/05/06/%e5%8a%a8%e6%80%81%e5%8a%a0%e8%bd%bdhive%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6%e7%9a%84%e6%96%b9%e6%a1%88/" >Spark动态加载hive配置的方案&lt;/a> ，当时是为了spark应用的fat-jar里面已经有Hadoop相关xml配置文件的情况下，将数据输出到不是该配置的Hadoop集群的方案。&lt;br>
现在这个需求有点类似，没有走spark-submit提交任务，而是在spark应用里面通过创建&lt;code>SparkContext&lt;/code>的形式提交任务，而spark应用的fat-jar里面已经有Hadoop相关xml配置文件，在此情况下，想将Spakr任务提交到外部的Yarn集群（不是fat-jar里面配置文件对应的yarn集群）。&lt;/p>
&lt;h2 id="思考一个问题">思考一个问题&lt;/h2>
&lt;p>先思考一个问题，如果Spark应用的fat-jar里面有外部Yarn集群对应的配置文件(&lt;code>core-site.xml&lt;/code>，&lt;code>hdfs-site.xml&lt;/code>，&lt;code>yarn-site.xml&lt;/code>等)，此时Spark应用代码里面创建&lt;code>SparkContext&lt;/code>，是不是就一定能提交到那个集群里？&lt;br>
可以做个实验，但实验不一定会cover到所有情况。&lt;br>
直接给结论吧，不一定能提交过去，但自己做实验的话很可能还是能直接提交过去的，还是直接看代码吧（以&lt;code>yarn-client&lt;/code>模式为例）。&lt;/p>
&lt;h3 id="spark-yarn-client-默认提交任务简析">Spark Yarn-client 默认提交任务简析&lt;/h3>
&lt;p>通过代码创建&lt;code>SparkContext&lt;/code>后，其动态代码块会根据启动模式创建&lt;code>SchedulerBackend&lt;/code>和&lt;code>TaskScheduler&lt;/code>并启动：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// org.apache.spark.SparkContext #501
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// Create and start the scheduler
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>sched&lt;span style="color:#5bc4bf">,&lt;/span> ts&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">SparkContext&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>createTaskScheduler&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">this&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> master&lt;span style="color:#5bc4bf">,&lt;/span> deployMode&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">_schedulerBackend&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> sched
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">_taskScheduler&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> ts
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">_dagScheduler&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">DAGScheduler&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">this&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// start TaskScheduler after taskScheduler sets DAGScheduler reference in DAGScheduler&amp;#39;s
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// constructor
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#fec418">_taskScheduler&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>start&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中 &lt;code>TaskScheduler&lt;/code> 是通过 &lt;code>org.apache.spark.scheduler.cluster.YarnClusterManager#createTaskScheduler&lt;/code> 创建的，对应 yarn-client 创建的是&lt;code>YarnScheduler&lt;/code>（继承了&lt;code>TaskSchedulerImpl&lt;/code>），start()方法调用到&lt;code>SchedulerBackend&lt;/code>的&lt;code>start&lt;/code>方法，后者就会创建yarn模式下的Client客户端（&lt;code>org.apache.spark.deploy.yarn.Client&lt;/code>，不是yarn自己那个client），并调用其&lt;code>submitApplication&lt;/code>方法提交任务到Yarn：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">//org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend#start
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">override&lt;/span> &lt;span style="color:#815ba4">def&lt;/span> start&lt;span style="color:#5bc4bf">()&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> driverHost &lt;span style="color:#815ba4">=&lt;/span> conf&lt;span style="color:#5bc4bf">.&lt;/span>get&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;spark.driver.host&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> driverPort &lt;span style="color:#815ba4">=&lt;/span> conf&lt;span style="color:#5bc4bf">.&lt;/span>get&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;spark.driver.port&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> hostport &lt;span style="color:#815ba4">=&lt;/span> driverHost &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;:&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> driverPort
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sc&lt;span style="color:#5bc4bf">.&lt;/span>ui&lt;span style="color:#5bc4bf">.&lt;/span>foreach &lt;span style="color:#5bc4bf">{&lt;/span> ui &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> conf&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;spark.driver.appUIAddress&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> ui&lt;span style="color:#5bc4bf">.&lt;/span>webUrl&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> argsArrayBuf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ArrayBuffer&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">]()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> argsArrayBuf &lt;span style="color:#5bc4bf">+=&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;--arg&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> hostport&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logDebug&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;ClientArguments called with: &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> argsArrayBuf&lt;span style="color:#5bc4bf">.&lt;/span>mkString&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34; &amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> args &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ClientArguments&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>argsArrayBuf&lt;span style="color:#5bc4bf">.&lt;/span>toArray&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> totalExpectedExecutors &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">YarnSparkHadoopUtil&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>getInitialTargetExecutorNumber&lt;span style="color:#5bc4bf">(&lt;/span>conf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> client &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">Client&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>args&lt;span style="color:#5bc4bf">,&lt;/span> conf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bindToYarn&lt;span style="color:#5bc4bf">(&lt;/span>client&lt;span style="color:#5bc4bf">.&lt;/span>submitApplication&lt;span style="color:#5bc4bf">(),&lt;/span> &lt;span style="color:#fec418">None&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//………………
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>初始化&lt;code>Client&lt;/code>的时候，会创建YarnConfiguration，此时就会读取到Configuration里面配置的默认资源，包括&lt;code>yarn-site.xml&lt;/code>等；如果fatjar里面放的是外部集群的配置文件，那么对应的&lt;code>YarnClient&lt;/code>就可以连接到外部Yarn集群。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">//org.apache.spark.deploy.yarn.Client
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>&lt;span style="color:#815ba4">private&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">spark&lt;/span>&lt;span style="color:#5bc4bf">]&lt;/span> &lt;span style="color:#815ba4">class&lt;/span> &lt;span style="color:#fec418">Client&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> args&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">ClientArguments&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> hadoopConf&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Configuration&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> sparkConf&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">SparkConf&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">extends&lt;/span> &lt;span style="color:#fec418">Logging&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//………………
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> yarnClient &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">YarnClient&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>createYarnClient
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> yarnConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">YarnConfiguration&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>hadoopConf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>接着刚才说到&lt;code>SchedulerBackend&lt;/code>调用&lt;code>Client&lt;/code>的&lt;code>submitApplication&lt;/code>方法:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">//org.apache.spark.deploy.yarn.Client#submitApplication
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">def&lt;/span> submitApplication&lt;span style="color:#5bc4bf">()&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">ApplicationId&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">var&lt;/span> appId&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">ApplicationId&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">try&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> launcherBackend&lt;span style="color:#5bc4bf">.&lt;/span>connect&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// Setup the credentials before doing anything else,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// so we have don&amp;#39;t have issues at any point.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> setupCredentials&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> yarnClient&lt;span style="color:#5bc4bf">.&lt;/span>init&lt;span style="color:#5bc4bf">(&lt;/span>yarnConf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> yarnClient&lt;span style="color:#5bc4bf">.&lt;/span>start&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logInfo&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Requesting a new application from cluster with %d NodeManagers&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">.&lt;/span>format&lt;span style="color:#5bc4bf">(&lt;/span>yarnClient&lt;span style="color:#5bc4bf">.&lt;/span>getYarnClusterMetrics&lt;span style="color:#5bc4bf">.&lt;/span>getNumNodeManagers&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// Get a new application from our RM
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">//新建一个Application
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> newApp &lt;span style="color:#815ba4">=&lt;/span> yarnClient&lt;span style="color:#5bc4bf">.&lt;/span>createApplication&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> newAppResponse &lt;span style="color:#815ba4">=&lt;/span> newApp&lt;span style="color:#5bc4bf">.&lt;/span>getNewApplicationResponse&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> appId &lt;span style="color:#815ba4">=&lt;/span> newAppResponse&lt;span style="color:#5bc4bf">.&lt;/span>getApplicationId&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">CallerContext&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;CLIENT&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> sparkConf&lt;span style="color:#5bc4bf">.&lt;/span>get&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">APP_CALLER_CONTEXT&lt;/span>&lt;span style="color:#5bc4bf">),&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">Option&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>appId&lt;span style="color:#5bc4bf">.&lt;/span>toString&lt;span style="color:#5bc4bf">)).&lt;/span>setCurrentContext&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// Verify whether the cluster has enough resources for our AM
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> verifyClusterResources&lt;span style="color:#5bc4bf">(&lt;/span>newAppResponse&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// Set up the appropriate contexts to launch our AM
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">//创建environment, java options以及启动AM的命令
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> containerContext &lt;span style="color:#815ba4">=&lt;/span> createContainerLaunchContext&lt;span style="color:#5bc4bf">(&lt;/span>newAppResponse&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//创建提交AM的Context，包括名字、队列、类型、内存、CPU及参数
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> appContext &lt;span style="color:#815ba4">=&lt;/span> createApplicationSubmissionContext&lt;span style="color:#5bc4bf">(&lt;/span>newApp&lt;span style="color:#5bc4bf">,&lt;/span> containerContext&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// Finally, submit and monitor the application
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> logInfo&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">s&amp;#34;Submitting application &lt;/span>&lt;span style="color:#f99b15">$appId&lt;/span>&lt;span style="color:#48b685"> to ResourceManager&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//向Yarn提交Application
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> yarnClient&lt;span style="color:#5bc4bf">.&lt;/span>submitApplication&lt;span style="color:#5bc4bf">(&lt;/span>appContext&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> launcherBackend&lt;span style="color:#5bc4bf">.&lt;/span>setAppId&lt;span style="color:#5bc4bf">(&lt;/span>appId&lt;span style="color:#5bc4bf">.&lt;/span>toString&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reportLauncherState&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">SparkAppHandle&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#fec418">State&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#fec418">SUBMITTED&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> appId
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span> &lt;span style="color:#815ba4">catch&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">case&lt;/span> e&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Throwable&lt;/span> &lt;span style="color:#5bc4bf">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>appId &lt;span style="color:#5bc4bf">!=&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cleanupStagingDir&lt;span style="color:#5bc4bf">(&lt;/span>appId&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">throw&lt;/span> e
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中 createContainerLaunchContext 会创建environment, java options以及启动AM的命令等，也会收集本地资源（&lt;code>prepareLocalResources&lt;/code>方法），其中包括&lt;code>__spark_conf__.zip&lt;/code>，在&lt;code>createConfArchive&lt;/code>方法中处理，压缩了本地的一些配置文件：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">def&lt;/span> createConfArchive&lt;span style="color:#5bc4bf">()&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">File&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> hadoopConfFiles &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">HashMap&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>, &lt;span style="color:#fec418">File&lt;/span>&lt;span style="color:#5bc4bf">]()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// Uploading $SPARK_CONF_DIR/log4j.properties file to the distributed cache to make sure that
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// the executors will use the latest configurations instead of the default values. This is
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// required when user changes log4j.properties directly to set the log configurations. If
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// configuration file is provided through --files then executors will be taking configurations
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// from --files instead of $SPARK_CONF_DIR/log4j.properties.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// Also uploading metrics.properties to distributed cache if exists in classpath.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// If user specify this file using --files then executors will use the one
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// from --files instead.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">for&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span> prop &lt;span style="color:#815ba4">&amp;lt;-&lt;/span> &lt;span style="color:#fec418">Seq&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;log4j.properties&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;metrics.properties&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url &lt;span style="color:#815ba4">&amp;lt;-&lt;/span> &lt;span style="color:#fec418">Option&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">Utils&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>getContextOrSparkClassLoader&lt;span style="color:#5bc4bf">.&lt;/span>getResource&lt;span style="color:#5bc4bf">(&lt;/span>prop&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> url&lt;span style="color:#5bc4bf">.&lt;/span>getProtocol &lt;span style="color:#5bc4bf">==&lt;/span> &lt;span style="color:#48b685">&amp;#34;file&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">}&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopConfFiles&lt;span style="color:#5bc4bf">(&lt;/span>prop&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">File&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>url&lt;span style="color:#5bc4bf">.&lt;/span>getPath&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">Seq&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;HADOOP_CONF_DIR&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;YARN_CONF_DIR&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>foreach &lt;span style="color:#5bc4bf">{&lt;/span> envKey &lt;span style="color:#815ba4">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sys&lt;span style="color:#5bc4bf">.&lt;/span>env&lt;span style="color:#5bc4bf">.&lt;/span>get&lt;span style="color:#5bc4bf">(&lt;/span>envKey&lt;span style="color:#5bc4bf">).&lt;/span>foreach &lt;span style="color:#5bc4bf">{&lt;/span> path &lt;span style="color:#815ba4">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> dir &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">File&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>path&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>dir&lt;span style="color:#5bc4bf">.&lt;/span>isDirectory&lt;span style="color:#5bc4bf">())&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> files &lt;span style="color:#815ba4">=&lt;/span> dir&lt;span style="color:#5bc4bf">.&lt;/span>listFiles&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>files &lt;span style="color:#5bc4bf">==&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logWarning&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Failed to list files under directory &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> dir&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span> &lt;span style="color:#815ba4">else&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> files&lt;span style="color:#5bc4bf">.&lt;/span>foreach &lt;span style="color:#5bc4bf">{&lt;/span> file &lt;span style="color:#815ba4">=&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>file&lt;span style="color:#5bc4bf">.&lt;/span>isFile &lt;span style="color:#5bc4bf">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#5bc4bf">!&lt;/span>hadoopConfFiles&lt;span style="color:#5bc4bf">.&lt;/span>contains&lt;span style="color:#5bc4bf">(&lt;/span>file&lt;span style="color:#5bc4bf">.&lt;/span>getName&lt;span style="color:#5bc4bf">()))&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopConfFiles&lt;span style="color:#5bc4bf">(&lt;/span>file&lt;span style="color:#5bc4bf">.&lt;/span>getName&lt;span style="color:#5bc4bf">())&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> file
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> confArchive &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">File&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>createTempFile&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">LOCALIZED_CONF_DIR&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;.zip&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">File&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">Utils&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>getLocalDir&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> confStream &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ZipOutputStream&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">FileOutputStream&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>confArchive&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//后面就是把这些文件写入到zip包的代码，略
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到，除了本地的&lt;code>log4j.properties&lt;/code>和&lt;code>metrics.properties&lt;/code>配置文件以外，还会读取&lt;code>HADOOP_CONF_DIR&lt;/code>和&lt;code>YARN_CONF_DIR&lt;/code>环境变量，读取对应目录下的文件放入&lt;code>hadoopConfFiles&lt;/code>这个&lt;code>HashMap&lt;/code>中，而这里面的文件都会压缩到&lt;code>__spark_conf__.zip&lt;/code>中。&lt;br>
再后续的代码就不分析了，可以参考网上其他文章。&lt;/p>
&lt;h3 id="提交外部yarn集群的障碍">提交外部Yarn集群的障碍&lt;/h3>
&lt;p>所以，如果执行spark应用程序的机器中配置了 &lt;em>HADOOP_CONF_DIR&lt;/em> 或 &lt;em>YARN_CONF_DIR&lt;/em> 环境变量（如HDP的节点安装了对应客户端都会配置上），在Spark提交任务到外部yarn集群的时候，就会将里面的配置文件压缩传输到外部集群的Executor节点，这样Executor的各种操作都会使用原集群的配置，连接不到正确的Yarn服务，最后也就导致任务执行失败。&lt;/p>
&lt;h2 id="解决方案">解决方案&lt;/h2>
&lt;p>所以解决整个提交外部集群的问题，有两个问题要处理：&lt;/p>
&lt;ol>
&lt;li>Spark应用代码使用外部集群的配置文件进行任务提交
&lt;ol>
&lt;li>一种方案是启动Spark应用后，创建&lt;code>SparkContext&lt;/code>之前，将外部集群的配置写入当前classpath的前面（如classpath是&lt;code>.:xxx.jar&lt;/code>，那么放在当前目录就可以）&lt;/li>
&lt;li>另一种方案是启动Spark应用前，将外部集群的配置写入当前目录，并通过&lt;code>jar uvf&lt;/code>打入jar包中；当然只是针对当前问题的话，无需打入jar包&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Spark准备executor的资源时，使用外部集群配置文件
&lt;ol>
&lt;li>一种方案是，创建&lt;code>SparkContext&lt;/code>之前，将&lt;code>HADOOP_CONF_DIR&lt;/code>和&lt;code>YARN_CONF_DIR&lt;/code>环境变量删除，提交任务后再恢复环境变量；这样不会把集群配置传给Executor，Executor使用的是fatjar包里面的配置文件，需要提前替换。&lt;/li>
&lt;li>另一种方案是，将外部集群的配置写入一个目录，并在创建&lt;code>SparkContext&lt;/code>之前，将&lt;code>HADOOP_CONF_DIR&lt;/code>和&lt;code>YARN_CONF_DIR&lt;/code>环境变量改为那个目录；这样正确的配置会传给Executor使用。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;p>结合起来最终的方案：&lt;/p>
&lt;ol>
&lt;li>外部集群的配置文件统一一个地方存储，可以直接存储在RDB。&lt;/li>
&lt;li>启动Spark应用的时候，检查需要提交到的Yarn集群，如果是外部集群，那么：
&lt;ol>
&lt;li>下载外部集群的配置文件到当前目录，同时复制到一个子目录里面&lt;/li>
&lt;li>将&lt;code>HADOOP_CONF_DIR&lt;/code>和&lt;code>YARN_CONF_DIR&lt;/code>环境变量改为那个子目录（不能用当前目录，因为当前目录包含fat-jar，根据代码jar包也会打包过去Executor）&lt;/li>
&lt;li>正常创建&lt;code>SparkContext&lt;/code>&lt;/li>
&lt;li>恢复环境变量&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;p>具体实现不外乎一些黑魔法（环境变量在JVM里面修改不了，但可以修改JVM用到的那个环境变量Map），再考虑下要不要放上来吧，反正这个最主要是思路和里面的坑。&lt;/p></description></item><item><title>Kettle Java API处理Hadoop数据</title><link>https://leibnizhu.github.io/p/Kettle-Java-API%E5%A4%84%E7%90%86Hadoop%E6%95%B0%E6%8D%AE/</link><pubDate>Tue, 15 May 2018 17:29:56 +0800</pubDate><guid>https://leibnizhu.github.io/p/Kettle-Java-API%E5%A4%84%E7%90%86Hadoop%E6%95%B0%E6%8D%AE/</guid><description>&lt;img src="https://leibnizhu.github.io/p/Kettle-Java-API%E5%A4%84%E7%90%86Hadoop%E6%95%B0%E6%8D%AE/yyz.jpg" alt="Featured image of post Kettle Java API处理Hadoop数据" />&lt;h2 id="前言">前言&lt;/h2>
&lt;p>最近因为数据处理的需求, 用到Kettle进行MySQL到HDFS的数据导入,而Kettle的GUI界面导入比较繁琐,不易于复用,所以考虑其Java API.&lt;br>
但是,网上的资料实在少得可怜, 而官网的文档也仅仅给出了一个例子,而且是版本很旧的. 于是只能根据这个很旧的版本, 加上Maven仓库摸索, 再加上官方最新版API文档,慢慢摸出来.&lt;/p>
&lt;h2 id="代码清单">代码清单&lt;/h2>
&lt;p>最后的结果就是这篇文章, 废话也不想多说了,也懒得打字,就是普通的Maven项目,主要三个文件:&lt;/p>
&lt;ol>
&lt;li>&lt;code>pom.xml&lt;/code>: Kettle依赖的版本比较麻烦,这个是个坑;&lt;/li>
&lt;li>一个Java示例文件, 放了一个&lt;code>MySQL =&amp;gt; MySQL&lt;/code> 和一个 &lt;code>MySQL =&amp;gt; HDFS&lt;/code> 的例子,详见注释;&lt;/li>
&lt;li>Java里面写了一个自动读取数据源的方法, 把所有用到的数据源按下文给定的xml格式配置好,放到&lt;code>resources/db&lt;/code>下面即可被程序读取.&lt;/li>
&lt;/ol>
&lt;h2 id="目录结构">目录结构&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>├── pom.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>└── src
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    ├── main
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   ├── java
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   │   └── com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   │      └── turingdi
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   │      └── kettle
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   │      └── demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   │      └── App.java
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   └── resources
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   ├── db
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   │   └── 235test.xml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    │   └── log4j.properties
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── test
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── java
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── turingdi
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── kettle
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── demo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>    └── AppTest.java
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="代码">代码&lt;/h2>
&lt;h3 id="pomxml">pom.xml&lt;/h3>
&lt;p>给出核心的变量和依赖部分:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">&amp;lt;properties&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;project.build.sourceEncoding&amp;gt;&lt;/span>UTF-8&lt;span style="color:#5bc4bf">&amp;lt;/project.build.sourceEncoding&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;maven.compiler.source&amp;gt;&lt;/span>1.8&lt;span style="color:#5bc4bf">&amp;lt;/maven.compiler.source&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;maven.compiler.target&amp;gt;&lt;/span>1.8&lt;span style="color:#5bc4bf">&amp;lt;/maven.compiler.target&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;pentaho.kettle.version&amp;gt;&lt;/span>4.1.0-stable&lt;span style="color:#5bc4bf">&amp;lt;/pentaho.kettle.version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;pentaho.kettle.plugin.version&amp;gt;&lt;/span>8.0.0.4-247&lt;span style="color:#5bc4bf">&amp;lt;/pentaho.kettle.plugin.version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/properties&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;repositories&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;repository&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;snapshots&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;enabled&amp;gt;&lt;/span>true&lt;span style="color:#5bc4bf">&amp;lt;/enabled&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;updatePolicy&amp;gt;&lt;/span>daily&lt;span style="color:#5bc4bf">&amp;lt;/updatePolicy&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/snapshots&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;id&amp;gt;&lt;/span>pentaho&lt;span style="color:#5bc4bf">&amp;lt;/id&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;url&amp;gt;&lt;/span>http://nexus.pentaho.org/content/groups/omni/&lt;span style="color:#5bc4bf">&amp;lt;/url&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/repository&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/repositories&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependencies&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho-kettle&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>kettle-core&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>${pentaho.kettle.plugin.version}&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho-kettle&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>kettle-db&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>4.4.0-stable&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho-kettle&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>kettle-engine&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>${pentaho.kettle.plugin.version}&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho-kettle&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>kettle-ui-swt&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>${pentaho.kettle.plugin.version}&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>pentaho-big-data-kettle-plugins-hdfs&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>${pentaho.kettle.plugin.version}&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>pentaho-big-data-api-hdfs&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>${pentaho.kettle.plugin.version}&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>pentaho-big-data-impl-cluster&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>${pentaho.kettle.plugin.version}&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">&amp;lt;!--插件所需依赖开始--&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>pentaho&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>metastore&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>${pentaho.kettle.plugin.version}&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>org.pentaho&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>pentaho-hadoop-shims-api&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>8.0-SNAPSHOT&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>commons-configuration&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>commons-configuration&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>1.9&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">&amp;lt;!--插件所需依赖结束--&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>org.apache.hadoop&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>hadoop-common&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>2.6.0-cdh5.9.3&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>org.apache.hadoop&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>hadoop-hdfs&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>2.6.0-cdh5.9.3&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>org.apache.hadoop&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>hadoop-client&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>2.6.0-cdh5.8.4&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>commons-logging&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>commons-logging&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>1.2&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>commons-vfs&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>commons-vfs&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>1.0&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>log4j&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>log4j&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>1.2.17&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>org.scannotation&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>scannotation&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>1.0.3&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclusions&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;exclusion&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>javassist&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>javassist&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/exclusion&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/exclusions&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>org.javassist&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>javassist&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>3.22.0-GA&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>com.turingdi&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>commonutils&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>1.0-SNAPSHOT&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>mysql&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>mysql-connector-java&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>5.1.41&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;groupId&amp;gt;&lt;/span>junit&lt;span style="color:#5bc4bf">&amp;lt;/groupId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;artifactId&amp;gt;&lt;/span>junit&lt;span style="color:#5bc4bf">&amp;lt;/artifactId&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;version&amp;gt;&lt;/span>4.11&lt;span style="color:#5bc4bf">&amp;lt;/version&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;scope&amp;gt;&lt;/span>test&lt;span style="color:#5bc4bf">&amp;lt;/scope&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependency&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/dependencies&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="java的示例">Java的示例&lt;/h3>
&lt;p>包含&lt;code>MySQL =&amp;gt; MySQL&lt;/code>和&lt;code>MySQL =&amp;gt; HDFS&lt;/code> 的方法:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">package&lt;/span> &lt;span style="color:#fec418">com.turingdi.kettle.demo&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">com.turingdi.commonutils.basic.FileUtils&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.big.data.api.cluster.NamedCluster&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.big.data.impl.cluster.NamedClusterImpl&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.big.data.impl.cluster.NamedClusterManager&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.big.data.impl.cluster.NamedClusterServiceOsgiImpl&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.big.data.kettle.plugins.hdfs.trans.HadoopFileOutputMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.cluster.ClusterSchema&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.Const&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.KettleEnvironment&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.NotePadMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.database.Database&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.database.DatabaseMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.exception.KettleException&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.plugins.PluginFolder&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.plugins.StepPluginType&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.core.util.EnvUtil&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.Trans&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.TransHopMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.TransMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.step.StepMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.steps.selectvalues.SelectValuesMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.steps.tableinput.TableInputMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.steps.tableoutput.TableOutputMeta&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.di.trans.steps.textfileoutput.TextFileField&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.runtime.test.action.impl.RuntimeTestActionServiceImpl&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">org.pentaho.runtime.test.impl.RuntimeTesterImpl&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">java.io.DataOutputStream&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">java.io.File&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">java.io.FileOutputStream&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">java.io.IOException&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">java.util.ArrayList&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">java.util.List&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">import&lt;/span> &lt;span style="color:#fec418">java.util.Objects&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">public&lt;/span> &lt;span style="color:#815ba4">class&lt;/span> &lt;span style="color:#fec418">App&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//存放读取到的xml字符串
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">static&lt;/span> String&lt;span style="color:#5bc4bf">[]&lt;/span> databasesXML&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//kettle插件的位置
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">static&lt;/span> &lt;span style="color:#815ba4">final&lt;/span> String KETTLE_PLUGIN_BASE_FOLDER &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;/Users/leibnizhu/Downloads/kettle/plugins&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">public&lt;/span> &lt;span style="color:#815ba4">static&lt;/span> &lt;span style="color:#fec418">void&lt;/span> &lt;span style="color:#06b6ef">main&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>String&lt;span style="color:#5bc4bf">[]&lt;/span> args&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#815ba4">throws&lt;/span> KettleException&lt;span style="color:#5bc4bf">,&lt;/span> IOException &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 这几句必须有, 官网例子是错的, 用来加载插件的
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> System&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setProperty&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hadoop.home.dir&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> StepPluginType&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getInstance&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>&lt;span style="color:#06b6ef">getPluginFolders&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>&lt;span style="color:#06b6ef">add&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> PluginFolder&lt;span style="color:#5bc4bf">(&lt;/span>KETTLE_PLUGIN_BASE_FOLDER&lt;span style="color:#5bc4bf">,&lt;/span>&lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">));&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> EnvUtil&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">environmentInit&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> KettleEnvironment&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">init&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 加载db目录下的所有存放数据库配置的xml文件
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// 这个在官方例子也是没有的, 自己写的, 而且没给出xml的例子, google到的一篇博客里面的, 坑死了
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String rootPath &lt;span style="color:#5bc4bf">=&lt;/span> App&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">class&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getResource&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;/&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>&lt;span style="color:#06b6ef">getPath&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> File dbDir &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> File&lt;span style="color:#5bc4bf">(&lt;/span>rootPath&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;db&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> List&lt;span style="color:#5bc4bf">&amp;lt;&lt;/span>String&lt;span style="color:#5bc4bf">&amp;gt;&lt;/span> xmlStrings &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> ArrayList&lt;span style="color:#5bc4bf">&amp;lt;&amp;gt;();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">for&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>File xml &lt;span style="color:#5bc4bf">:&lt;/span> Objects&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">requireNonNull&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>dbDir&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">listFiles&lt;/span>&lt;span style="color:#5bc4bf">()))&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>xml&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">isFile&lt;/span>&lt;span style="color:#5bc4bf">()&lt;/span> &lt;span style="color:#5bc4bf">&amp;amp;&amp;amp;&lt;/span> xml&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getName&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>&lt;span style="color:#06b6ef">endsWith&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;.xml&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">))&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> xmlStrings&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">add&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>FileUtils&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">ReadFile&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>xml&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getAbsolutePath&lt;/span>&lt;span style="color:#5bc4bf">()));&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> databasesXML &lt;span style="color:#5bc4bf">=&lt;/span> xmlStrings&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">toArray&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> String&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#f99b15">0&lt;/span>&lt;span style="color:#5bc4bf">]);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 调用下面的方法, 创建一个复制数据库表的Transform任务
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// TransMeta transMeta = buildCopyTable(
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// &amp;#34;trans&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// &amp;#34;235test&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// &amp;#34;user&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// new String[]{&amp;#34;id&amp;#34;, &amp;#34;name&amp;#34;},
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// &amp;#34;235test&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// &amp;#34;user2&amp;#34;,
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// new String[]{&amp;#34;id2&amp;#34;, &amp;#34;name2&amp;#34;}
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// );
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> TransMeta transMeta &lt;span style="color:#5bc4bf">=&lt;/span> buildCopyTableToHDFS&lt;span style="color:#5bc4bf">(&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;trans&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;235test&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;user&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">new&lt;/span> String&lt;span style="color:#5bc4bf">[]{&lt;/span>&lt;span style="color:#48b685">&amp;#34;id&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;name&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 把以上transform保存到文件, 这样可以用Spoon打开,检查下有没有问题
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String fileName &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;/Users/leibnizhu/Desktop/test.ktr&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String xml &lt;span style="color:#5bc4bf">=&lt;/span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getXML&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DataOutputStream dos &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> DataOutputStream&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> FileOutputStream&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> File&lt;span style="color:#5bc4bf">(&lt;/span>fileName&lt;span style="color:#5bc4bf">)));&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dos&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">write&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>xml&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getBytes&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;UTF-8&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">));&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dos&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">close&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> System&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">out&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">println&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Saved transformation to file: &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> fileName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 生成SQL,用于创建表(如果不存在的话)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String sql &lt;span style="color:#5bc4bf">=&lt;/span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getSQLStatementsString&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 执行以上SQL语句创建表
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> Database targetDatabase &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> Database&lt;span style="color:#5bc4bf">(&lt;/span>transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">findDatabase&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;235test&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">));&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> targetDatabase&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">connect&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> targetDatabase&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">execStatements&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sql&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 执行transformation...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> Trans trans &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> Trans&lt;span style="color:#5bc4bf">(&lt;/span>transMeta&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> trans&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">execute&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">null&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> trans&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">waitUntilFinished&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 断开数据库连接
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> targetDatabase&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">disconnect&lt;/span>&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">/**
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * Creates a new Transformation using input parameters such as the tablename to read from.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> *
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param transformationName The name of the transformation
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param sourceDatabaseName 数据源, 对应xml里面的name字段
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param sourceTableName The name of the table to read from
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param sourceFields The field names we want to read from the source table
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param targetDatabaseName 复制的去向, 对应xml里面的name字段
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param targetTableName The name of the target table we want to write to
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param targetFields The names of the fields in the target table (same number of fields as sourceFields)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @return A new transformation metadata object
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @throws KettleException In the rare case something goes wrong
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> */&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">static&lt;/span> TransMeta &lt;span style="color:#06b6ef">buildCopyTable&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>String transformationName&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String sourceDatabaseName&lt;span style="color:#5bc4bf">,&lt;/span> String sourceTableName&lt;span style="color:#5bc4bf">,&lt;/span> String&lt;span style="color:#5bc4bf">[]&lt;/span> sourceFields&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String targetDatabaseName&lt;span style="color:#5bc4bf">,&lt;/span> String targetTableName&lt;span style="color:#5bc4bf">,&lt;/span> String&lt;span style="color:#5bc4bf">[]&lt;/span> targetFields&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">throws&lt;/span> KettleException &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">try&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 创建transformation...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> TransMeta transMeta &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TransMeta&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setName&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>transformationName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 增加数据库连接的元数据
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">for&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>String aDatabasesXML &lt;span style="color:#5bc4bf">:&lt;/span> databasesXML&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DatabaseMeta databaseMeta &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> DatabaseMeta&lt;span style="color:#5bc4bf">(&lt;/span>aDatabasesXML&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addDatabase&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>databaseMeta&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DatabaseMeta sourceDBInfo &lt;span style="color:#5bc4bf">=&lt;/span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">findDatabase&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sourceDatabaseName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DatabaseMeta targetDBInfo &lt;span style="color:#5bc4bf">=&lt;/span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">findDatabase&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>targetDatabaseName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 增加备注
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String note &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;Reads information from table [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;] on database [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceDBInfo &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> Const&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">CR&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;After that, it writes the information to table [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> targetTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;] on database [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> targetDBInfo &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> NotePadMeta ni &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> NotePadMeta&lt;span style="color:#5bc4bf">(&lt;/span>note&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">150&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">10&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#5bc4bf">-&lt;/span>&lt;span style="color:#f99b15">1&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#5bc4bf">-&lt;/span>&lt;span style="color:#f99b15">1&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addNote&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>ni&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 创建读数据库的step
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String fromStepName &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;read from [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> TableInputMeta tii &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TableInputMeta&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tii&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDatabaseMeta&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sourceDBInfo&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tii&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setSQL&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;SELECT &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> Const&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">CR&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> String&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">join&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;,&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> sourceFields&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34; &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;FROM &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> StepMeta fromStep &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> StepMeta&lt;span style="color:#5bc4bf">(&lt;/span>fromStepName&lt;span style="color:#5bc4bf">,&lt;/span> tii&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//以下几句是给Spoon看的, 用处不大
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> fromStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setLocation&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">150&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">100&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fromStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDraw&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fromStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDescription&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Reads information from table [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;] on database [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceDBInfo &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addStep&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>fromStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 创建一个修改字段名的step
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> SelectValuesMeta svi &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> SelectValuesMeta&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//配置字段名修改的规则, 这里跟官方例子差别很大, 坑不少
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> svi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">allocate&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sourceFields&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">length&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">0&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">0&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">for&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">int&lt;/span> i &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#f99b15">0&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span> i &lt;span style="color:#5bc4bf">&amp;lt;&lt;/span> sourceFields&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">length&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span> i&lt;span style="color:#5bc4bf">++)&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> svi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getSelectName&lt;/span>&lt;span style="color:#5bc4bf">()[&lt;/span>i&lt;span style="color:#5bc4bf">]&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> sourceFields&lt;span style="color:#5bc4bf">[&lt;/span>i&lt;span style="color:#5bc4bf">];&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> svi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">getSelectRename&lt;/span>&lt;span style="color:#5bc4bf">()[&lt;/span>i&lt;span style="color:#5bc4bf">]&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> targetFields&lt;span style="color:#5bc4bf">[&lt;/span>i&lt;span style="color:#5bc4bf">];&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String selStepName &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;Rename field names&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> StepMeta selStep &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> StepMeta&lt;span style="color:#5bc4bf">(&lt;/span>selStepName&lt;span style="color:#5bc4bf">,&lt;/span> svi&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//以下几句是给Spoon看的, 用处不大
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> selStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setLocation&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">350&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">100&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> selStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDraw&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> selStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDescription&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Rename field names&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addStep&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>selStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//建立读数据库step与修改字段名step的连接,增加到transformation中
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> TransHopMeta shi &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TransHopMeta&lt;span style="color:#5bc4bf">(&lt;/span>fromStep&lt;span style="color:#5bc4bf">,&lt;/span> selStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addTransHop&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>shi&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 创建一个输出到表的step
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String toStepName &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;write to [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> targetTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> TableOutputMeta toi &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TableOutputMeta&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDatabaseMeta&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>targetDBInfo&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setTablename&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>targetTableName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setCommitSize&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">200&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setTruncateTable&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setSchemaName&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;test&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toi&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setTruncateTable&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">false&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> StepMeta toStep &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> StepMeta&lt;span style="color:#5bc4bf">(&lt;/span>toStepName&lt;span style="color:#5bc4bf">,&lt;/span> toi&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//以下几句是给Spoon看的, 用处不大
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> toStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setLocation&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">550&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">100&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDraw&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> toStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDescription&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Write information to table [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> targetTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;] on database [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> targetDBInfo &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addStep&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>toStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 建立修改字段名step到输出到数据库step的连接
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> TransHopMeta hi &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TransHopMeta&lt;span style="color:#5bc4bf">(&lt;/span>selStep&lt;span style="color:#5bc4bf">,&lt;/span> toStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addTransHop&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>hi&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 返回
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">return&lt;/span> transMeta&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span> &lt;span style="color:#815ba4">catch&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>Exception e&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">throw&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> KettleException&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;An unexpected error occurred creating the new transformation&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> e&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#815ba4">static&lt;/span> TransMeta &lt;span style="color:#06b6ef">buildCopyTableToHDFS&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>String transformationName&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String sourceDatabaseName&lt;span style="color:#5bc4bf">,&lt;/span> String sourceTableName&lt;span style="color:#5bc4bf">,&lt;/span> String&lt;span style="color:#5bc4bf">[]&lt;/span> sourceFields&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">throws&lt;/span> KettleException &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">try&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 创建transformation...
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> TransMeta transMeta &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TransMeta&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setName&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>transformationName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 增加数据库连接的元数据
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">for&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>String aDatabasesXML &lt;span style="color:#5bc4bf">:&lt;/span> databasesXML&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DatabaseMeta databaseMeta &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> DatabaseMeta&lt;span style="color:#5bc4bf">(&lt;/span>aDatabasesXML&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addDatabase&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>databaseMeta&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DatabaseMeta sourceDBInfo &lt;span style="color:#5bc4bf">=&lt;/span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">findDatabase&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sourceDatabaseName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 增加备注
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String note &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;Reads information from table [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;] on database [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceDBInfo &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> Const&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">CR&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;After that, it writes the information to HDFS ]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> NotePadMeta ni &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> NotePadMeta&lt;span style="color:#5bc4bf">(&lt;/span>note&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">150&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">10&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#5bc4bf">-&lt;/span>&lt;span style="color:#f99b15">1&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#5bc4bf">-&lt;/span>&lt;span style="color:#f99b15">1&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addNote&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>ni&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 创建读数据库的step
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> String fromStepName &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;read from [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> TableInputMeta tii &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TableInputMeta&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tii&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDatabaseMeta&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sourceDBInfo&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tii&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setSQL&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;SELECT &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> Const&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">CR&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> String&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">join&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;,&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> sourceFields&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34; &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;FROM &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> StepMeta fromStep &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> StepMeta&lt;span style="color:#5bc4bf">(&lt;/span>fromStepName&lt;span style="color:#5bc4bf">,&lt;/span> tii&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//以下几句是给Spoon看的, 用处不大
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> fromStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setLocation&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">150&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">100&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fromStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDraw&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fromStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDescription&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Reads information from table [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceTableName &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;] on database [&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> sourceDBInfo &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;]&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addStep&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>fromStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> NamedClusterManager clusterManager &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> NamedClusterManager&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> NamedCluster cluster &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> NamedClusterImpl&lt;span style="color:#5bc4bf">();&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setStorageScheme&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hdfs&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setHdfsHost&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;bitest01&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setHdfsPort&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;8020&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setName&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;cloudera&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setHdfsUsername&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setHdfsPassword&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> clusterManager&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setClusterTemplate&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>cluster&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// transMeta.setNamedClusterServiceOsgi();
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// clusterManager.getClusterTemplate().setHdfsHost(&amp;#34;bitest01&amp;#34;);
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> HadoopFileOutputMeta hadoopOut &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> HadoopFileOutputMeta&lt;span style="color:#5bc4bf">(&lt;/span>clusterManager&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// new RuntimeTestActionServiceImpl(null, null),
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">// new RuntimeTesterImpl(null, null, &amp;#34;test&amp;#34;));
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setOutputFields&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> TextFileField&lt;span style="color:#5bc4bf">[]{});&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setFilename&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hdfs://bitest01:8020/tmp/aa&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setExtension&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;txt&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setFileCompression&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;None&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setSourceConfigurationName&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;Cloudera&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setSeparator&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;,&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setFileFormat&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;UNIX&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopOut&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setEncoding&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;UTF-8&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> StepMeta hadoopStep &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> StepMeta&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;HDFSOutput&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> hadoopOut&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setLocation&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">550&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">100&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hadoopStep&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">setDraw&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">true&lt;/span>&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addStep&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>hadoopStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> TransHopMeta hhm &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> TransHopMeta&lt;span style="color:#5bc4bf">(&lt;/span>fromStep&lt;span style="color:#5bc4bf">,&lt;/span> hadoopStep&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transMeta&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#06b6ef">addTransHop&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>hhm&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 返回
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">return&lt;/span> transMeta&lt;span style="color:#5bc4bf">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span> &lt;span style="color:#815ba4">catch&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>Exception e&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">throw&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> KettleException&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;An unexpected error occurred creating the new transformation&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> e&lt;span style="color:#5bc4bf">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="存储数据库源配置的xml文件">存储数据库源配置的xml文件&lt;/h3>
&lt;p>放在&lt;code>resources/db&lt;/code>下面:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">&amp;lt;connection&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;name&amp;gt;&lt;/span>test&lt;span style="color:#5bc4bf">&amp;lt;/name&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;server&amp;gt;&lt;/span>192.168.1.*&lt;span style="color:#5bc4bf">&amp;lt;/server&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;type&amp;gt;&lt;/span>MySQL&lt;span style="color:#5bc4bf">&amp;lt;/type&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;access&amp;gt;&lt;/span>Native&lt;span style="color:#5bc4bf">&amp;lt;/access&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;database&amp;gt;&lt;/span>test&lt;span style="color:#5bc4bf">&amp;lt;/database&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;port&amp;gt;&lt;/span>3306&lt;span style="color:#5bc4bf">&amp;lt;/port&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;username&amp;gt;&lt;/span>root&lt;span style="color:#5bc4bf">&amp;lt;/username&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;password&amp;gt;&lt;/span>root&lt;span style="color:#5bc4bf">&amp;lt;/password&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;servername/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;data_tablespace/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;index_tablespace/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attributes&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;code&amp;gt;&lt;/span>EXTRA_OPTION_MYSQL.defaultFetchSize&lt;span style="color:#5bc4bf">&amp;lt;/code&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>500&lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;code&amp;gt;&lt;/span>EXTRA_OPTION_MYSQL.useCursorFetch&lt;span style="color:#5bc4bf">&amp;lt;/code&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>true&lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;code&amp;gt;&lt;/span>EXTRA_OPTION_MYSQL.useSSL&lt;span style="color:#5bc4bf">&amp;lt;/code&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>false&lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;code&amp;gt;&lt;/span>EXTRA_OPTION_MYSQL.useUnicode&lt;span style="color:#5bc4bf">&amp;lt;/code&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>true&lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;code&amp;gt;&lt;/span>EXTRA_OPTION_MYSQL.characterEncoding&lt;span style="color:#5bc4bf">&amp;lt;/code&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;attribute&amp;gt;&lt;/span>UTF-8&lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/attribute&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">&amp;lt;/attributes&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">&amp;lt;/connection&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Kerberos集群的Sqoop,Hive,HBase,Kafka,Maxwell使用</title><link>https://leibnizhu.github.io/p/Kerberos%E9%9B%86%E7%BE%A4%E7%9A%84SqoopHiveHBaseKafkaMaxwell%E4%BD%BF%E7%94%A8/</link><pubDate>Wed, 07 Mar 2018 16:23:56 +0800</pubDate><guid>https://leibnizhu.github.io/p/Kerberos%E9%9B%86%E7%BE%A4%E7%9A%84SqoopHiveHBaseKafkaMaxwell%E4%BD%BF%E7%94%A8/</guid><description>&lt;img src="https://leibnizhu.github.io/p/Kerberos%E9%9B%86%E7%BE%A4%E7%9A%84SqoopHiveHBaseKafkaMaxwell%E4%BD%BF%E7%94%A8/flower.jpg" alt="Featured image of post Kerberos集群的Sqoop,Hive,HBase,Kafka,Maxwell使用" />&lt;p>介绍在部署了Kerberos的安全Hadoop集群中, Sqoop,Hive,HBase,Kafka,Maxwell使用方法.&lt;/p>
&lt;h2 id="sqoop使用">Sqoop使用&lt;/h2>
&lt;p>配置好Kerberos之后, sqoop不能直接使用, 需要进行一些配置:&lt;/p>
&lt;ol>
&lt;li>分配sqoop的组, 执行&lt;code>usermod -a -G hdfs sqoop&lt;/code>加入到hdfs组, 使用&lt;code>groups sqoop&lt;/code>确认执行成功;&lt;/li>
&lt;li>进入Hue的用户管理界面, 新增sqoop用户, 在hdfs用户组中;&lt;/li>
&lt;li>在Hue的HDFS文件管理页面中, 创建/user/sqoop目录, 从属于sqoop:hdfs用户/用户组;&lt;/li>
&lt;li>进入cdh1, 创建Kerberos用户, 名为sqoop, 可以导出keytab;&lt;/li>
&lt;li>使用kinit命令切换到sqoop用户(在脚本中可以使用keytab切换)&lt;/li>
&lt;li>执行sqoop命令&lt;/li>
&lt;/ol>
&lt;h2 id="spark访问hbase">Spark访问HBase&lt;/h2>
&lt;ol>
&lt;li>进入cdh1, 创建Kerberos用户, 名为hbase; 导出keytab, 名为hbase.keytab, 保存到本地;&lt;/li>
&lt;li>下载krb5.conf到本地.&lt;/li>
&lt;li>创建测试类, 并执行, 代码如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">/*HBase测试*/&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">object&lt;/span> &lt;span style="color:#fec418">KerberosHBaseTest&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> main&lt;span style="color:#5bc4bf">(&lt;/span>args&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Array&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">])&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> zkHosts &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;cdh2:2181,cdh3:2181,cdh4:2181&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//krb5.conf本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkConf&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>setAppName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosHBaseTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>setMaster&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> sc &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkContext&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//配置HBase连接
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> hbaseConfig &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">HBaseConfiguration&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>create&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.zookeeper.quorum&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> zkHosts&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;zookeeper.znode.parent&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/hbase&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//设置集群和hbase的安全模式为kerberos
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hadoop.security.authentication&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;kerberos&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.security.authentication&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;kerberos&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.master.kerberos.principal&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;hbase/_HOST@TURINGDI.COM&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//没有似乎也行
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.regionserver.kerberos.principal&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;hbase/_HOST@TURINGDI.COM&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setConfiguration&lt;span style="color:#5bc4bf">(&lt;/span>hbaseConfig&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>loginUserFromKeytab&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/hbase.keytab&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//Kerberos用户名, keytab本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">//设置广播变量，解决序列化问题
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">//HBase配置
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> broadcastHBaseConf &lt;span style="color:#815ba4">=&lt;/span> sc&lt;span style="color:#5bc4bf">.&lt;/span>broadcast&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SerializableWritable&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>hbaseConfig&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//HBase连接工具类
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> hbaseConnection &lt;span style="color:#815ba4">=&lt;/span> sc&lt;span style="color:#5bc4bf">.&lt;/span>broadcast&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">HBaseConnection&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>broadcastHBaseConf&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> result &lt;span style="color:#815ba4">=&lt;/span> scanByStartTimestamp&lt;span style="color:#5bc4bf">(&lt;/span>hbaseConnection&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;t1&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">0L&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result&lt;span style="color:#5bc4bf">.&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>r &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> println&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">ConvertService&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>convertResultToHBaseRow&lt;span style="color:#5bc4bf">(&lt;/span>r&lt;span style="color:#5bc4bf">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sc&lt;span style="color:#5bc4bf">.&lt;/span>stop&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">/**
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * 从HBase中scan指定表的所有列，从指定的时间戳开始
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> *
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param hBaseConnection HBase连接
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param tableName 表名
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param starTimestamp 开始scan的时间戳，从该时间戳scan到当前时间
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @return scan的结果，Result的List
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @author Leibniz
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> */&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> scanByStartTimestamp&lt;span style="color:#5bc4bf">(&lt;/span>hBaseConnection&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Broadcast&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">HBaseConnection&lt;/span>&lt;span style="color:#5bc4bf">],&lt;/span> tableName&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> starTimestamp&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Long&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">ArrayBuffer&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">Result&lt;/span>&lt;span style="color:#5bc4bf">]&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> resultList &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ArrayBuffer&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">Result&lt;/span>&lt;span style="color:#5bc4bf">]()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">Try&lt;/span>&lt;span style="color:#5bc4bf">({&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> scan &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">Scan&lt;/span>&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scan&lt;span style="color:#5bc4bf">.&lt;/span>setTimeRange&lt;span style="color:#5bc4bf">(&lt;/span>starTimestamp&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>currentTimeMillis&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 获取表
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> table &lt;span style="color:#815ba4">=&lt;/span> hBaseConnection&lt;span style="color:#5bc4bf">.&lt;/span>value&lt;span style="color:#5bc4bf">.&lt;/span>connection&lt;span style="color:#5bc4bf">.&lt;/span>getTable&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">TableName&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>valueOf&lt;span style="color:#5bc4bf">(&lt;/span>tableName&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> table&lt;span style="color:#5bc4bf">.&lt;/span>getScanner&lt;span style="color:#5bc4bf">(&lt;/span>scan&lt;span style="color:#5bc4bf">).&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>resultList&lt;span style="color:#5bc4bf">.+=)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}).&lt;/span>recover&lt;span style="color:#5bc4bf">({&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">case&lt;/span> e&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Throwable&lt;/span> &lt;span style="color:#5bc4bf">=&amp;gt;&lt;/span> log&lt;span style="color:#5bc4bf">.&lt;/span>error&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;从HBase表{}中按时间戳({}-&amp;gt;NOW)scan时抛出异常:{}&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">Seq&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">AnyRef&lt;/span>&lt;span style="color:#5bc4bf">](&lt;/span>tableName&lt;span style="color:#5bc4bf">,&lt;/span> starTimestamp&lt;span style="color:#5bc4bf">.&lt;/span>toString&lt;span style="color:#5bc4bf">,&lt;/span> e&lt;span style="color:#5bc4bf">.&lt;/span>getMessage&lt;span style="color:#5bc4bf">)&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#815ba4">_&lt;/span>&lt;span style="color:#fec418">*&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resultList
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="spark访问hive">Spark访问Hive&lt;/h2>
&lt;ol>
&lt;li>Hive可以沿用hbase的Kerberos用户, 也可以新建一个Hive用户及其对应keytab文件.&lt;/li>
&lt;li>本地测试请将集群的&lt;code>hive-site.xml&lt;/code>导出并保存在项目的&lt;code>src/main/resources/&lt;/code>目录下;&lt;/li>
&lt;li>编写Spark测试程序:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">/*Hive测试*/&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">object&lt;/span> &lt;span style="color:#fec418">KerberosHiveTest&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> main&lt;span style="color:#5bc4bf">(&lt;/span>args&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Array&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">])&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//krb5.conf本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkConf&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>setAppName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosHiveTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>setMaster&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> sc &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkContext&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> config &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">HBaseConfiguration&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>create&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> config&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hadoop.security.authentication&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;kerberos&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setConfiguration&lt;span style="color:#5bc4bf">(&lt;/span>config&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>loginUserFromKeytab&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/hbase.keytab&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//Kerberos用户名, keytab本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkSession &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">SparkSession&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>builder&lt;span style="color:#5bc4bf">.&lt;/span>master&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>appName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosHiveTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>enableHiveSupport&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">.&lt;/span>config&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;yarn.resourcemanager.principal&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;rm/_HOST@TURINGDI.COM&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// .config(&amp;#34;spark.yarn.keytab&amp;#34;, &amp;#34;/path/to/hbase.keytab&amp;#34;)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// .config(&amp;#34;spark.yarn.principal&amp;#34;, &amp;#34;hbase@TURINGDI.COM&amp;#34;)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#5bc4bf">.&lt;/span>getOrCreate&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> dataFrame &lt;span style="color:#815ba4">=&lt;/span> sparkSession&lt;span style="color:#5bc4bf">.&lt;/span>sql&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;select * from hivetest2&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dataFrame&lt;span style="color:#5bc4bf">.&lt;/span>rdd&lt;span style="color:#5bc4bf">.&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>row &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> println&lt;span style="color:#5bc4bf">(&lt;/span>row&lt;span style="color:#5bc4bf">.&lt;/span>getInt&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">0&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34; -&amp;gt; &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> row&lt;span style="color:#5bc4bf">.&lt;/span>getString&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">1&lt;/span>&lt;span style="color:#5bc4bf">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sc&lt;span style="color:#5bc4bf">.&lt;/span>stop&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="spark访问kafka">Spark访问Kafka&lt;/h2>
&lt;ol>
&lt;li>进入Cloudera Manager的Kafka配置页面, 搜索&amp;rsquo;Inter Broker Protocol&amp;rsquo;, 更改为&amp;rsquo;SASL_PLAINTEXT';&lt;/li>
&lt;li>重启Kafka配置;&lt;/li>
&lt;li>进入cdh1, 创建Kerberos用户, 名为kafka; 导出keytab, 名为kafka.keytab, 并保存到本地(测试用);&lt;/li>
&lt;li>cdh1中新建一个jaas.conf配置文件, 并复制到本地(注意修改keyTab), 内容如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>KafkaClient &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> com.sun.security.auth.module.Krb5LoginModule required
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">doNotPrompt&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">useTicketCache&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">useKeyTab&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">principal&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;kafka@TURINGDI.COM&amp;#34;&lt;/span> &lt;span style="color:#776e71">#根据实际修改&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">serviceName&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;kafka&amp;#34;&lt;/span> &lt;span style="color:#776e71">## 固定&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">client&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">keyTab&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;/path/to/kafka.keytab&amp;#34;&lt;/span>; &lt;span style="color:#776e71">## keytab路径,节点和本地按实际路径填写&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="5">
&lt;li>cdh1中新建一个kafka.properties文件, 内容如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-conf" data-lang="conf">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">security.protocol&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">SASL_PLAINTEXT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">sasl.kerberos.service.name&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">kafka&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">sasl.mechanism&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">GSSAPI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">security.inter.broker.protocol&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">SASL_PLAINTEXT&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="6">
&lt;li>编写Spark程序进行测试:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">object&lt;/span> &lt;span style="color:#fec418">KerberosKafkaTest&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> main&lt;span style="color:#5bc4bf">(&lt;/span>args&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Array&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">])&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> zkHosts &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;cdh2:2181,cdh3:2181,cdh4:2181&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> kafkaBrokers &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;cdh2:9092,cdh3:9092,cdh4:9092&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> topics &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">List&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;maxwell&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//本地krb5.conf路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.auth.login.config&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/jaas.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>&lt;span style="color:#776e71">//本地jaas.conf路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// 创建流处理上下文，并以启动参数指定的秒数为时间间隔做一次批处理。
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkConf&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>setAppName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosKafkaTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;spark.streaming.kafka.consumer.poll.ms&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">KAFKA_CONSUMER_POLL_MS&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>setMaster&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> ssc &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">StreamingContext&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">Seconds&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">10&lt;/span>&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 配置并创建Kafka输入流
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// 如果zookeeper没有offset值或offset值超出范围，就给个初始的offset
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// 有earliest、largest可选，分别表示给当前最小的offset、当前最大的offset。默认largest
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> kafkaParams &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">Map&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>, &lt;span style="color:#fec418">Object&lt;/span>&lt;span style="color:#5bc4bf">](&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;auto.offset.reset&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;earliest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;bootstrap.servers&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> kafkaBrokers&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;group.id&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;testGroup&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;enable.auto.commit&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">false&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">java.lang.Boolean&lt;/span>&lt;span style="color:#5bc4bf">),&lt;/span> &lt;span style="color:#776e71">//禁用自动提交Offset，否则可能没正常消费完就提交了，造成数据错误
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#48b685">&amp;#34;key.deserializer&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> classOf&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">StringDeserializer&lt;/span>&lt;span style="color:#5bc4bf">],&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;value.deserializer&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> classOf&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">StringDeserializer&lt;/span>&lt;span style="color:#5bc4bf">],&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;sasl.kerberos.service.name&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;kafka&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#48b685">&amp;#34;security.protocol&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;SASL_PLAINTEXT&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//与Kafka配置一致
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> kafkaStream &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">KafkaUtils&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>createDirectStream&lt;span style="color:#5bc4bf">(&lt;/span>ssc&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">PreferConsistent&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">ConsumerStrategies&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#fec418">Subscribe&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>topics&lt;span style="color:#5bc4bf">,&lt;/span> kafkaParams&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kafkaStream&lt;span style="color:#5bc4bf">.&lt;/span>foreachRDD&lt;span style="color:#5bc4bf">(&lt;/span>rdd &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log&lt;span style="color:#5bc4bf">.&lt;/span>info&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;接收到{}条Kafka消息&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> rdd&lt;span style="color:#5bc4bf">.&lt;/span>count&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rdd&lt;span style="color:#5bc4bf">.&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>message &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> println&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;partition=&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> message&lt;span style="color:#5bc4bf">.&lt;/span>partition &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;, value=&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> message&lt;span style="color:#5bc4bf">.&lt;/span>value &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;, offset=&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> message&lt;span style="color:#5bc4bf">.&lt;/span>offset&lt;span style="color:#5bc4bf">.&lt;/span>toString&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ssc&lt;span style="color:#5bc4bf">.&lt;/span>start&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ssc&lt;span style="color:#5bc4bf">.&lt;/span>awaitTermination&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="7">
&lt;li>kafka自带的命令, 如kafka-console-consumer, kafka-topics还不能使用, 若要使用, 需要先执行:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>export &lt;span style="color:#ef6155">KAFKA_OPTS&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;-Djava.security.krb5.conf=/etc/krb5.conf -Djava.security.auth.login.config=/path/to/jaas.conf&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意修改其中的jass.conf路径, 并确保其中配置的keytab存在; 再执行相应的kafka命令.&lt;br>
如果觉得麻烦, 也可以编辑&lt;code>/opt/cloudera/parcels/KAFKA-3.0.0-1.3.0.0.p0.40/lib/kafka/bin/kafka-run-class.sh&lt;/code>, 在&lt;code>exec $JAVA&lt;/code>后面增加:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>-Djava.security.krb5.conf&lt;span style="color:#5bc4bf">=&lt;/span>/etc/krb5.conf -Djava.security.auth.login.config&lt;span style="color:#5bc4bf">=&lt;/span>/root/jaas.conf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="maxwell配置">Maxwell配置&lt;/h2>
&lt;ol>
&lt;li>编辑${MAXWELL_HOME}/bin/maxwell, 在文件尾部附件的&lt;code>exec $JAVA $JAVA_OPTS&lt;/code>后面增加:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>-Djava.security.krb5.conf&lt;span style="color:#5bc4bf">=&lt;/span>/etc/krb5.conf -Djava.security.auth.login.config&lt;span style="color:#5bc4bf">=&lt;/span>/root/jaas.conf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>编辑一个config.properties文件, 内容如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-conf" data-lang="conf">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">kafka.security.protocol&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">SASL_PLAINTEXT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">kafka.sasl.kerberos.service.name&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">kafka&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">kafka.sasl.mechanism&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">GSSAPI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">security.inter.broker.protocol&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">SASL_PLAINTEXT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">sasl.mechanism.inter.broker.protocol&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#ef6155">PLAIN&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>在maxwell启动命令中增加参数:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>--config /path/to/config.properties
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Kerberos部署,配置与基础使用</title><link>https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</link><pubDate>Wed, 07 Mar 2018 16:23:33 +0800</pubDate><guid>https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</guid><description>&lt;img src="https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/room.jpg" alt="Featured image of post Kerberos部署,配置与基础使用" />&lt;p>下文以本地测试集群为例, 4节点(cdh1-4), cdh1为NameNode, cdh2-4为DataNode.&lt;/p>
&lt;h2 id="基础概念">基础概念&lt;/h2>
&lt;p>Kerberos principal用于在kerberos加密系统中标记一个唯一的身份。&lt;br>
kerberos为kerberos principal分配tickets使其可以访问由kerberos加密的hadoop服务。&lt;br>
对于hadoop，principals的格式为username/fully.qualified.domain.name@YOUR-REALM.COM.&lt;br>
keytab是包含principals和加密principal key的文件。&lt;br>
keytab文件对于每个host是唯一的，因为key中包含hostname。keytab文件用于不需要人工交互和保存纯文本密码，实现到kerberos上验证一个主机上的principal。&lt;br>
因为服务器上可以访问keytab文件即可以以principal的身份通过kerberos的认证，所以，keytab文件应该被妥善保存，应该只有少数的用户可以访问。&lt;/p>
&lt;h2 id="kdc服务安装及配置">KDC服务安装及配置&lt;/h2>
&lt;h3 id="安装kdc服务">安装KDC服务&lt;/h3>
&lt;p>选择NameNode节点(cdh1)安装KDC服务, 执行:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>yum -y install krb5-server krb5-libs krb5-auth-dialog krb5-workstation openldap-clients
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其他节点(cdh2-4)只安装Kerberos客户端, 执行:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>yum -y install krb5-libs krb5-workstation
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="配置kdc服务">配置KDC服务&lt;/h3>
&lt;p>1.编辑/etc/krb5.conf:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">## Configuration snippets may be placed in this directory as well&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>includedir /etc/krb5.conf.d/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">[&lt;/span>logging&lt;span style="color:#5bc4bf">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">default&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> FILE:/var/log/krb5libs.log
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">kdc&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> FILE:/var/log/krb5kdc.log
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">admin_server&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> FILE:/var/log/kadmind.log
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">[&lt;/span>libdefaults&lt;span style="color:#5bc4bf">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">dns_lookup_realm&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> false
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">dns_lookup_kdc&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> false
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">ticket_lifetime&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> 24h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">renew_lifetime&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> 7d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">forwardable&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#rdns = false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ef6155">default_realm&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> TURINGDI.COM &lt;span style="color:#776e71">#随意定义一个域&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#default_ccache_name = KEYRING:persistent:%{uid}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">[&lt;/span>realms&lt;span style="color:#5bc4bf">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">#与上面default_realm一致, 配置KDC服务所在的服务器&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>TURINGDI.COM &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">kdc&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> cdh1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">admin_server&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> cdh1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">[&lt;/span>domain_realm&lt;span style="color:#5bc4bf">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>.turingdi.com &lt;span style="color:#5bc4bf">=&lt;/span> TURINGDI.COM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>turingdi.com &lt;span style="color:#5bc4bf">=&lt;/span> TURINGDI.COM
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>2.将/etc/krb5.conf复制到每个节点的/etc/目录下.&lt;br>
3.修改/var/kerberos/krb5kdc/kadm5.acl, 配置用户名包含/admin的用户都是管理员用户:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>*/admin@TURINGDI.COM *
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>4.修改修改/var/kerberos/krb5kdc/kdc.conf, 配置令牌的生命周期, 并设置默认允许重新生成令牌:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">[&lt;/span>kdcdefaults&lt;span style="color:#5bc4bf">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">kdc_ports&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#f99b15">88&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">kdc_tcp_ports&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#f99b15">88&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">[&lt;/span>realms&lt;span style="color:#5bc4bf">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>TURINGDI.COM &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">#master_key_type = aes256-cts&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">max_renewable_life&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span> 7d 0h 0m 0s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">default_principal_flags&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> +renewable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">acl_file&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> /var/kerberos/krb5kdc/kadm5.acl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">dict_file&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> /usr/share/dict/words
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">admin_keytab&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> /var/kerberos/krb5kdc/kadm5.keytab
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">supported_enctypes&lt;/span> &lt;span style="color:#5bc4bf">=&lt;/span> aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="创建kerberos数据库">创建Kerberos数据库&lt;/h3>
&lt;p>在cdh1执行以下命令, 注意域名:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kdb5_util create –r TURINGDI.COM -s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>按提示设置密码并重复密码.&lt;/p>
&lt;h3 id="创建kerberos的管理账号">创建Kerberos的管理账号&lt;/h3>
&lt;p>在cdh1执行:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kadmin.local
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>依次输入:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>addprinc admin/admin@TURINGDI.COM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">## 按提示设置管理账号的密码并重复密码&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>exit
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="配置服务自启动">配置服务自启动&lt;/h3>
&lt;p>在cdh1执行:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>chkconfig krb5kdc on
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>hkconfig kadmin on
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>service krb5kdc start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>service kadmin start
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后尝试登陆Kerberos的管理员账号:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kinit admin/admin@TURINGDI.COM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">## 3. 输入刚才设定的管理账号密码&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>klist
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>应该会输出类似:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>Ticket cache: FILE:/tmp/krb5cc_0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Default principal: admin/admin@TURINGDI.COM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Valid starting Expires Service principal
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2018-03-06T16:48:23 2018-03-07T16:48:23 krbtgt/TURINGDI.COM@TURINGDI.COM
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> renew &lt;span style="color:#815ba4">until&lt;/span> 2018-03-13T16:48:23
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>即配置成功.&lt;/p>
&lt;h2 id="cdh集群启用kerberos">CDH集群启用Kerberos&lt;/h2>
&lt;ol>
&lt;li>进入Cloudera Manager的“管理”-&amp;gt; “安全”界面:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/security.png"
width="1544"
height="360"
srcset="https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/security_huf4677ec2483774f32c9e9eb7c2f66152_14138_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/security_huf4677ec2483774f32c9e9eb7c2f66152_14138_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="428"
data-flex-basis="1029px"
>&lt;/li>
&lt;li>点击&amp;quot;启用Kerberos&amp;quot;按钮, 确保列出的所有检查项都已完成并勾选, 点击&amp;quot;继续&amp;quot;按钮:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/keberosList.png"
width="1268"
height="926"
srcset="https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/keberosList_hud19fe07c80291333b2cbcc5eb0726cd4_22242_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/keberosList_hud19fe07c80291333b2cbcc5eb0726cd4_22242_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="136"
data-flex-basis="328px"
>&lt;/li>
&lt;li>配置相关的KDC信息，包括类型、KDC服务器、KDC Realm、加密类型以及待创建的Service Principal（hdfs，yarn,，hbase，hive等）的更新生命期等, 与/etc/krb5.conf的配置一致, 点击&amp;quot;继续&amp;quot;按钮.&lt;/li>
&lt;li>取消勾选&amp;quot;通过Cloudera Manager管理krb5.conf&amp;quot;, 点击&amp;quot;继续&amp;quot;按钮.&lt;/li>
&lt;li>输入Cloudera Manager的Kerbers管理员账号，必须和之前创建的账号一致，点击&amp;quot;继续&amp;quot;.&lt;/li>
&lt;li>最后点击&amp;quot;继续&amp;quot;, 勾选重启集群, 点击&amp;quot;继续&amp;quot;按钮, 等待配置重启集群.&lt;/li>
&lt;/ol>
&lt;h2 id="aes-256加密与jce">AES-256加密与JCE&lt;/h2>
&lt;p>对于使用centos5.6及以上的系统，默认使用AES-256来加密的。这就需要集群中的所有节点上安装JCE.&lt;br>
打开&lt;a class="link" href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener"
>http://www.oracle.com/technetwork/java/javase/downloads/index.html&lt;/a>, 下载jdk对应的JCE文件.&lt;br>
解压后的文件放入&lt;code>${JAVA_HOME}/jre/lib/security/&lt;/code>中.&lt;/p>
&lt;h2 id="kerberos的基础使用">Kerberos的基础使用&lt;/h2>
&lt;h3 id="yarn配置">Yarn配置&lt;/h3>
&lt;p>打开Cloudera Manager的Yarn配置页面, 搜索min.user, 修改为0, 然后按提示重启Yarn.&lt;br>
使用Kerberos需要新建一些用户, 其id可能小于1000, 使用Yarn的默认配置可能会导致一些用户不能提交Yarn任务.&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/yarn.png"
width="1880"
height="1048"
srcset="https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/yarn_hu8c2909963a12b977c7fae31cbd96c112_53756_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Kerberos%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/yarn_hu8c2909963a12b977c7fae31cbd96c112_53756_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="179"
data-flex-basis="430px"
>&lt;/p>
&lt;h3 id="导出keytab">导出keytab&lt;/h3>
&lt;p>进入cdh1, 输入&lt;code>kadmin.local&lt;/code>, 输入以下命令:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>xst -k /path/to/*.keytab -norandkey &amp;lt;principal&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中principal为需要导出keytab的用户名, 如hbase/cdh2, 注意-norandkey参数不可缺少, 否则可能会导致重新生成密码, 导致keytab失效.&lt;br>
导出的keytab的效用等同账号密码, 请注意妥善保管.&lt;/p>
&lt;h3 id="以某个kerberos用户登录">以某个Kerberos用户登录&lt;/h3>
&lt;p>两种方法:&lt;/p>
&lt;ol>
&lt;li>&lt;code>kinit 用户名@域名&lt;/code>, 输入密码;&lt;/li>
&lt;li>&lt;code>kinit 用户名@域名 -k -t 对应keytab文件&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>后者无需输入密码, 适合在脚本中使用.&lt;br>
一些组件对Kerberos的令牌有限制, 需要登录对应用户后才能使用, 包括HDFS的文件访问控制, 需要在Kerberos中建立对应的用户.&lt;/p>
&lt;h3 id="创建kerberos用户">创建Kerberos用户&lt;/h3>
&lt;p>前面已经使用过了, 进入cdh1, 输入&lt;code>kadmin.local&lt;/code>, 输入以下命令:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>addprinc 用户名@域名
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">## 按提示设置管理账号的密码并重复密码&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Sentry部署,配置与使用</title><link>https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/</link><pubDate>Wed, 07 Mar 2018 16:23:22 +0800</pubDate><guid>https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid><description>&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/summer.jpg" alt="Featured image of post Sentry部署,配置与使用" />&lt;p>最近在CDH集群部署Sentry和Kerberos遇到了不少坑, 把过程总结一下, 都放上来吧.&lt;/p>
&lt;h2 id="sentry组件安装">Sentry组件安装&lt;/h2>
&lt;p>进入Cloudera Manager页面, 点击集群名右边的倒三角按钮, 选择&amp;quot;添加服务&amp;quot;:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/add.png"
width="844"
height="478"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/add_huc0b99d23dde631907b537bf95a0319d0_11156_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/add_huc0b99d23dde631907b537bf95a0319d0_11156_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="176"
data-flex-basis="423px"
>&lt;br>
选择Sentry组件, 点击&amp;quot;继续&amp;quot;:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addSentry.png"
width="2422"
height="530"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addSentry_hu71bcaa3408fb3e02ca5f307a4516805a_48368_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addSentry_hu71bcaa3408fb3e02ca5f307a4516805a_48368_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="456"
data-flex-basis="1096px"
>&lt;br>
选择集群主节点作为Sentry Server, 选择所有节点为Gateway, 然后点击&amp;quot;继续&amp;quot;:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/selectServer.png"
width="1596"
height="468"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/selectServer_hu1561b49df4de1a4512187ef712b567b8_29750_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/selectServer_hu1561b49df4de1a4512187ef712b567b8_29750_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="341"
data-flex-basis="818px"
>&lt;br>
在集群元数据MySQL中执行:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">create&lt;/span> &lt;span style="color:#815ba4">database&lt;/span> sentry &lt;span style="color:#815ba4">default&lt;/span> character &lt;span style="color:#815ba4">set&lt;/span> utf8 &lt;span style="color:#815ba4">default&lt;/span> &lt;span style="color:#815ba4">collate&lt;/span> utf8_general_ci;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">grant&lt;/span> &lt;span style="color:#815ba4">all&lt;/span> &lt;span style="color:#815ba4">on&lt;/span> sentry.&lt;span style="color:#5bc4bf">*&lt;/span> &lt;span style="color:#815ba4">to&lt;/span> &lt;span style="color:#48b685">&amp;#39;sentry&amp;#39;&lt;/span>&lt;span style="color:#5bc4bf">@&lt;/span>&lt;span style="color:#48b685">&amp;#39;%&amp;#39;&lt;/span> identified &lt;span style="color:#815ba4">by&lt;/span> &lt;span style="color:#48b685">&amp;#39;sentrypassword&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>创建Sentry所需的数据库, 然后在Sentry安装页面中填上MySQL的地址账号密码, 点击继续, 等待安装和首次启动完毕.&lt;/p>
&lt;h2 id="sentry及相关组件配置">Sentry及相关组件配置&lt;/h2>
&lt;h3 id="hue配置">Hue配置&lt;/h3>
&lt;p>进入Hue配置, 找到&amp;quot;Sentry 服务&amp;quot;, 选择Sentry:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHue.png"
width="970"
height="160"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHue_huddb9b871f0d068303146905e0f4d8291_3928_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHue_huddb9b871f0d068303146905e0f4d8291_3928_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="606"
data-flex-basis="1455px"
>&lt;/p>
&lt;h2 id="hive配置">Hive配置&lt;/h2>
&lt;p>进入Hive配置, 找到&amp;quot;Sentry 服务&amp;quot;, 选择Sentry:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive1.png"
width="946"
height="170"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive1_hu641b9b64e8f2f3de50783ed177ccf2c9_4084_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive1_hu641b9b64e8f2f3de50783ed177ccf2c9_4084_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="556"
data-flex-basis="1335px"
>&lt;br>
找到&amp;quot;HiveServer2 启用模拟&amp;quot;, 取消勾选:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive2.png"
width="1136"
height="128"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive2_hu3da2be25e9f7490b486730954d6f40b5_6992_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive2_hu3da2be25e9f7490b486730954d6f40b5_6992_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="887"
data-flex-basis="2130px"
>&lt;br>
找到&amp;quot;sentry-site.xml 的 Hive 服务高级配置代码段（安全阀）&amp;quot;, 增加&lt;code>sentry.hive.testing.mode&lt;/code>属性, 值为&lt;code>true&lt;/code>:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive3.png"
width="1558"
height="418"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive3_hu311c356bdaa4e60a0f13ab6a6457bb33_10980_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHive3_hu311c356bdaa4e60a0f13ab6a6457bb33_10980_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="372"
data-flex-basis="894px"
>&lt;/p>
&lt;h3 id="impala配置">Impala配置&lt;/h3>
&lt;p>注: 需要确认集群每个节点都安装了Impala Daemon服务;如果Impala启动时提示cannot read or execute the parent directory of dfs.domain.socket.path, 则HDFS配置的dfs.client.read.shortcircuit勾选上, 并创建dfs.domain.socket.path的目录.&lt;br>
进入Impala配置, 找到&amp;quot;Sentry 服务&amp;quot;, 选择Sentry:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setImpala.png"
width="1008"
height="180"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setImpala_hu51c1747fd172fc43081df8420f271252_4268_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setImpala_hu51c1747fd172fc43081df8420f271252_4268_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="560"
data-flex-basis="1344px"
>&lt;/p>
&lt;h3 id="hdfs配置">HDFS配置&lt;/h3>
&lt;p>进入HDFS配置, 找到&amp;quot;启用访问控制列表 dfs.namenode.acls.enabled&amp;quot;, 勾选:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHdfs.png"
width="1032"
height="114"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHdfs_hu3b0e990228748f4b3a91fa73898a15ec_4978_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/setHdfs_hu3b0e990228748f4b3a91fa73898a15ec_4978_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="905"
data-flex-basis="2172px"
>&lt;/p>
&lt;h3 id="重启集群">重启集群&lt;/h3>
&lt;p>Cloudera Manager会提示过期配置需要重启组件, 点击黄色圆形箭头, 点击&amp;quot;重启过时服务&amp;quot;, 并等待重启完成:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/change.png"
width="742"
height="1202"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/change_hudac6d6a8132b5ae7cce3acf822283987_27474_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/change_hudac6d6a8132b5ae7cce3acf822283987_27474_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="61"
data-flex-basis="148px"
>&lt;/p>
&lt;h2 id="hue用户权限配置">Hue用户权限配置&lt;/h2>
&lt;h3 id="前提">前提&lt;/h3>
&lt;p>Hue的用户权限体系是: 每个用户属于一个或多个组, 每个组可以配置其Hue页面访问权限及Hive/Solr/HDFS数据访问权限, 数据的访问权限由角色定义, 而用户组和角色之间是多对多关系.&lt;br>
Hue使用Sentry进行权限管理之后, 要求登录Hue的用户及其组需要在Sentry Server节点(以正式环境为例, 即gs01节点)Linux系统中存在对应的用户和组, 否则无法进行权限控制.&lt;br>
目前已经在Hue创建了一个hdfs用户组(拥有最高权限), 包含用户admin及hdfs, 两者在gs01节点Linux系统中均存在. hdfs用户的存在主要考虑到Spark程序通过hue的oozie工作流提交时, 保证其执行权限.&lt;br>
下文假定需要建立一个用户组hiveselect和用户hive1, 允许登录, 拥有部分hive表的select权限.&lt;/p>
&lt;h3 id="创建linux用户">创建Linux用户&lt;/h3>
&lt;p>ssh登录gs01节点, 执行:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>groupadd hiveselect
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>useradd -f hiveselect hive1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>P.S. 上面命令建立的用户是没有密码的, 需要密码或其他选项的请自行添加参数.&lt;/p>
&lt;h3 id="创建hue用户">创建Hue用户&lt;/h3>
&lt;p>使用admin或hdfs用户登录Hue, 点击右上角用户名, 选择&amp;quot;Manage users&amp;quot;:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser.png"
width="446"
height="324"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser_hu504f2689fd0a898237e09ec7be11f7a8_6242_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser_hu504f2689fd0a898237e09ec7be11f7a8_6242_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="137"
data-flex-basis="330px"
>&lt;br>
点击&amp;quot;Group&amp;quot;选项卡, 点击&amp;quot;Add Group&amp;quot;按钮, &amp;ldquo;Name&amp;quot;填Linux的组名&amp;quot;hiveselect&amp;rdquo;, &amp;ldquo;members&amp;quot;为该组用户, 可以后期选择, &amp;ldquo;permissions&amp;quot;是该组用户的Hue页面访问权限, 其中&amp;quot;beeswax.access:Launch this application(2)&amp;ldquo;必选; 如果需要hive查询, 则需要选择&amp;quot;metadata.access:Launch this application(23)&amp;ldquo;和&amp;quot;metastore.access:Launch this application(12)&amp;rdquo;, 其他组件请根据具体需求而勾选:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addGroup1.png"
width="2058"
height="426"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addGroup1_hu0e94cd056a87e61551acccec8e8c4a1b_19824_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addGroup1_hu0e94cd056a87e61551acccec8e8c4a1b_19824_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="483"
data-flex-basis="1159px"
>&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addGroup2.png"
width="1630"
height="1484"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addGroup2_hu0201b2a533c6dc3c455a702c91ef4dfa_32918_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addGroup2_hu0201b2a533c6dc3c455a702c91ef4dfa_32918_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="109"
data-flex-basis="263px"
>&lt;br>
然后点击&amp;quot;Add group&amp;quot;按钮增加组.&lt;/p>
&lt;p>随后点击&amp;quot;Users&amp;quot;选项卡, 点击&amp;quot;Add user&amp;quot;按钮, Step 1填用户名(与Linux用户名一致)和Hue登录密码, Step 2选择所属用户组为&amp;quot;hiveselect&amp;rdquo;(与Linux用户组一致), 最后点击&amp;quot;Add user&amp;quot;按钮:
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser1.png"
width="2002"
height="342"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser1_hu53755ed6163210200dadcf90ac68d272_13536_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser1_hu53755ed6163210200dadcf90ac68d272_13536_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="585"
data-flex-basis="1404px"
>&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser2.png"
width="1138"
height="592"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser2_huafb58769bb3a4a402249e03fe66bedde_16000_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser2_huafb58769bb3a4a402249e03fe66bedde_16000_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="192"
data-flex-basis="461px"
>&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser3.png"
width="1134"
height="970"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser3_hu1a14d567fa49eb4b36fbe4d2e0688003_17858_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addUser3_hu1a14d567fa49eb4b36fbe4d2e0688003_17858_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="116"
data-flex-basis="280px"
>&lt;/p>
&lt;h3 id="配置角色权限">配置角色权限&lt;/h3>
&lt;p>点击左上角≡按钮, 再点击&amp;quot;Security&amp;rdquo;, 选择Hive Tables选项卡, 进行Hive访问权限配置.&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/menu.png"
width="554"
height="984"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/menu_hu09ed838551ac7e0c9b8d6dab7f40a8e7_10854_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/menu_hu09ed838551ac7e0c9b8d6dab7f40a8e7_10854_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="56"
data-flex-basis="135px"
>&lt;br>
左侧选择Roles, 点击右边的&amp;quot;Add&amp;quot;按钮, &amp;ldquo;Name&amp;quot;中填写角色名, 可随意填写, &amp;ldquo;Groups&amp;quot;选择需要授予该角色的用户组, 此处选择了我们现在要处理的hiveselect用户组, &amp;ldquo;Privileges&amp;quot;中点击加号, 增加权限, 可以填写权限类型(select/insert/all), 及对应权限的库/表/列, 一个角色可以增加多条权限规则:&lt;br>
&lt;img src="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addRole.png"
width="2094"
height="828"
srcset="https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addRole_hu99d195eb2dd894836bad9caf7521805b_16790_480x0_resize_box_3.png 480w, https://leibnizhu.github.io/p/Sentry%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/addRole_hu99d195eb2dd894836bad9caf7521805b_16790_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="252"
data-flex-basis="606px"
>&lt;br>
填写完毕之后, 点击Save按钮, 稍等片刻即可生效(按目前经验来看, 新增的组可能需要3-5分钟才能生效, 已经配置过的组修改访问权限的话几乎是立刻生效).&lt;/p>
&lt;h3 id="hive最高权限">Hive最高权限&lt;/h3>
&lt;p>Hue中配置的Hive权限是针对表的读写权限的, 并没有涉及到建库建表的权限, 使用管理员用户可以赋予该权限, 进入hue
的Hive编辑器, 执行:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">grant&lt;/span> &lt;span style="color:#815ba4">all&lt;/span> &lt;span style="color:#815ba4">on&lt;/span> server server1 &lt;span style="color:#815ba4">to&lt;/span> &lt;span style="color:#815ba4">role&lt;/span> hue&lt;span style="color:#ef6155">角色名&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>