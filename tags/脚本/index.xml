<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>脚本 on Heaven's Door</title><link>https://leibnizhu.github.io/tags/%E8%84%9A%E6%9C%AC/</link><description>Recent content in 脚本 on Heaven's Door</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 22 Apr 2017 19:34:10 +0800</lastBuildDate><atom:link href="https://leibnizhu.github.io/tags/%E8%84%9A%E6%9C%AC/index.xml" rel="self" type="application/rss+xml"/><item><title>HBase外网同步脚本</title><link>https://leibnizhu.github.io/p/HBase%E5%A4%96%E7%BD%91%E5%90%8C%E6%AD%A5%E8%84%9A%E6%9C%AC/</link><pubDate>Sat, 22 Apr 2017 19:34:10 +0800</pubDate><guid>https://leibnizhu.github.io/p/HBase%E5%A4%96%E7%BD%91%E5%90%8C%E6%AD%A5%E8%84%9A%E6%9C%AC/</guid><description>&lt;h2 id="问题">问题&lt;/h2>
&lt;p>我们用多台云服务器搭建了HDP的hadoop集群，为了方便测试，在本地用virtualbox虚拟机搭建了一个架构完全一样的集群。为了测试程序，训练模型，本地的集群的数据也需要与云服务器上集群的一样。&lt;br>
MySQL数据库可以通过主从备份实时同步，而HBase数据在配置同步的过程中就遇到了问题，常规的方法无法完成同步。&lt;/p>
&lt;h2 id="常规方法">常规方法&lt;/h2>
&lt;p>HBase可以设置备份，然而只能在同一个内网，而我们不想搭建vpn。&lt;br>
然后是借助sqoop之类的工具，我们尝试对zookeeper等相关使用的端口开启内网映射，然而还是无法从外网访问，检查了iptables，没发现问题，原因未知。&lt;/p>
&lt;h2 id="最终方案">最终方案&lt;/h2>
&lt;p>最后采用了最暴力的方案，就是使用HBase自带的export和import功能，把云端HBase整个表导出到文件再导入到本地集群HBase，缺点是慢，因为是通过mapReduce操作完成的，数据量大的时候尤其慢。而且不知为何，无法直接导出到本地文件系统，只能通过HDFS文件系统中转，也就是说，整个同步流程是：&lt;/p>
&lt;ol>
&lt;li>云端HBase数据库表export到云端HDFS&lt;/li>
&lt;li>云端HDFS的导出文件导出到云端Linux文件系统&lt;/li>
&lt;li>本地集群通过scp下载云端的导出文件（因为安全问题，这里还分了两部，先scp下载到我的电脑，再scp上传到本地集群）&lt;/li>
&lt;li>本地集群HDFS导入下载到的备份文件&lt;/li>
&lt;li>本地集群HBase数据库import备份文件&lt;/li>
&lt;/ol>
&lt;p>整个过程比较麻烦，所以我写了个脚本，通过crontab每15分钟定时执行，脚本内容如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">#!/bin/bash&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ssh 服务器名 &amp;gt; /dev/null 2&amp;gt;&amp;amp;&lt;span style="color:#f99b15">1&lt;/span> &lt;span style="color:#48b685">&amp;lt;&amp;lt; eeooff
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> set HADOOP_USER_NAME=hdfs
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> rm -rf /root/share
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> hadoop fs -rm -r -f -skipTrash /backup/表名
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> whoami
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> /usr/hdp/current/hbase-client/bin/hbase org.apache.hadoop.hbase.mapreduce.Driver export &amp;#39;表名&amp;#39; /backup/表名
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> hadoop fs -get /backup/表名 ~/bakcup
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> exit
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> eeooff&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rm -rf /home/***/tmp/backup
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scp -r 服务器名:/root/backup/ /home/***/tmp/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scp -r /home/***/tmp/backup 本地集群主机名:/home/hdfs/
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ssh 本地集群主机名 &amp;gt; /dev/null 2&amp;gt;&amp;amp;&lt;span style="color:#f99b15">1&lt;/span> &lt;span style="color:#48b685">&amp;lt;&amp;lt; eeooff
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> set HADOOP_USER_NAME=hdfs
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> su - hdfs
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> hadoop fs -rm -r -f -skipTrash /backup/表名
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> hadoop fs -put /home/hdfs/backup /test
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> /usr/hdp/current/hbase-client/bin/hbase org.apache.hadoop.hbase.mapreduce.Driver import &amp;#39;SHARE_CHAIN&amp;#39; /backup/表名
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#48b685"> eeooff&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>