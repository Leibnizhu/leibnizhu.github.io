<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hive on Heaven's Door</title><link>https://leibnizhu.github.io/tags/Hive/</link><description>Recent content in Hive on Heaven's Door</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 06 May 2020 13:10:28 +0800</lastBuildDate><atom:link href="https://leibnizhu.github.io/tags/Hive/index.xml" rel="self" type="application/rss+xml"/><item><title>Spark动态加载hive配置的方案</title><link>https://leibnizhu.github.io/p/Spark%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDhive%E9%85%8D%E7%BD%AE%E7%9A%84%E6%96%B9%E6%A1%88/</link><pubDate>Wed, 06 May 2020 13:10:28 +0800</pubDate><guid>https://leibnizhu.github.io/p/Spark%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDhive%E9%85%8D%E7%BD%AE%E7%9A%84%E6%96%B9%E6%A1%88/</guid><description>&lt;img src="https://leibnizhu.github.io/p/Spark%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDhive%E9%85%8D%E7%BD%AE%E7%9A%84%E6%96%B9%E6%A1%88/bg3.jpg" alt="Featured image of post Spark动态加载hive配置的方案" />&lt;p>一般来说，Spark写Hive，把&lt;code>xxx-site.xml&lt;/code>系列配置文件打进jar包里，或&lt;code>spark-submit&lt;/code>指定下file之类，new个&lt;code>HiveContext&lt;/code>就完事了。&lt;br>
要写外部集群，也不外乎是换对应的&lt;code>xxx-site.xml&lt;/code>，改改&lt;code>thrift&lt;/code>服务地址啥的，不费劲。&lt;br>
好了，本文结束。&lt;br>
&lt;br/>
&lt;br/>
&lt;br/>
&lt;br/>
&lt;br/>
&lt;br/>
&lt;br/>
&lt;br/>
&lt;br/>
不对，擅长断更的我不会为此特意写篇博客。&lt;br>
现在的场景是，每次Spark任务启动的时候才能拿到外部Hive集群的配置信息（别问我为什么，问就是中台的需求，很多集群，java应用启动后才能去读到任务配置，反射组装RDD并执行，Hive配置？lazy的，到写入的时候才会去拿）。&lt;br>
这个过程踩了不少坑，试了几种方案，直接说结论吧。&lt;/p>
&lt;ol>
&lt;li>&lt;code>SparkContext&lt;/code>创建的时候会创建一个&lt;code>Configuration&lt;/code>对象（注意 &lt;code>loadDefaults=true&lt;/code>)，写入Hive会用到它；而这个&lt;code>Configuration&lt;/code>对象里面已经放了常规的那些&lt;code>***-site.xml&lt;/code>系列配置文件作为 &lt;code>defaultResources&lt;/code>，这时写入Hive相当于按fat-jar里面的配置来了；&lt;/li>
&lt;li>围观&lt;code>Configuration&lt;/code>代码，reload配置之后会将&lt;code>defaultResources&lt;/code>逐个读出，而&lt;code>defaultResources&lt;/code>是个有序的List，那么显然可以用&lt;code>Configuration#addDefaultResource()&lt;/code>把外部集群的相关配置xml设置为默认资源，这样拿配置的时候就会拿到外部集群的配置啦！！！&lt;/li>
&lt;li>为了方便配置的读取，直接放在hdfs吧，这样直接&lt;code>Configuration.addDefaultResource(&amp;quot;hdfs:///path/to/hive-site.xml&amp;quot;)&lt;/code>不就可以了吗？诶怎么不行，再围观&lt;code>Configuration&lt;/code>代码，可以看到加载默认资源最终用的是&lt;code>Configuration#getResource()&lt;/code>方法，这个方法体就一句话：&lt;code>return classLoader.getResource(name);&lt;/code>，也就是说，它不会去解析hdfs协议，而是直接从classpath里面去读取。所以不能直接从hdfs读取；&lt;/li>
&lt;li>最后的方案是把配置文件放在hdfs，写入Hive前，把它下载到当前classpath的其中某个目录下（比如classpath包含&lt;code>.&lt;/code> 则下载到&lt;code>System.getProperty(&amp;quot;user.dir&amp;quot;)&lt;/code>下），然后&lt;code>Configuration.addDefaultResource(&amp;quot;hive-site.xml&amp;quot;)&lt;/code>，因为&lt;code>Configuration&lt;/code>是用&lt;code>ClassLoader&lt;/code>进行加载的，所以注意路径没有&lt;code>/&lt;/code>。&lt;/li>
&lt;li>这就完事了？并不，跑起来会发现还是查询jar包里的hive metastore地址，所以还要解析&lt;code>hive-site.xml&lt;/code>，读取出&lt;code>hive.metastore.uris&lt;/code>值并放入环境变量中。&lt;/li>
&lt;li>这就完事了？并不，考虑到后续还会有其他写入操作，以及&lt;code>SparkContext.stop()&lt;/code>操作，这些操作都会用到&lt;code>Configuration&lt;/code>读取配置，然而现在以及有了外部集群的默认资源了，需要删掉，然而&lt;code>Configuration&lt;/code>并没有提供删除默认资源的方法，所以这里要手动反射删除之。&lt;/li>
&lt;/ol>
&lt;p>最终代码（简化版）：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">@Slf4j&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">class&lt;/span> &lt;span style="color:#fec418">WriteExtraHive&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">public&lt;/span> &lt;span style="color:#815ba4">static&lt;/span> &lt;span style="color:#815ba4">final&lt;/span> String HIVE_METASTORE_URIS_KEY &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;hive.metastore.uris&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">public&lt;/span> &lt;span style="color:#815ba4">static&lt;/span> &lt;span style="color:#815ba4">final&lt;/span> String BASE_HDFS_PATH &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#fec418">boolean&lt;/span> useSparkSql; &lt;span style="color:#776e71">//实际的实现是支持走jdbc和走SparkSql，根据是否有hive的配置文件&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> Set&lt;span style="color:#5bc4bf">&amp;lt;&lt;/span>String&lt;span style="color:#5bc4bf">&amp;gt;&lt;/span> extraDefaultResource &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> HashSet&lt;span style="color:#5bc4bf">&amp;lt;&amp;gt;&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> String hosts; &lt;span style="color:#776e71">//集群节点，这里只用于区分hdfs的配置路径&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">public&lt;/span> &lt;span style="color:#fec418">void&lt;/span> &lt;span style="color:#06b6ef">write&lt;/span>(){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> init(); &lt;span style="color:#776e71">//加载配置&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> write(); &lt;span style="color:#776e71">//真正写hive&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> end(); &lt;span style="color:#776e71">//移除额外添加的默认资源&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">public&lt;/span> &lt;span style="color:#fec418">void&lt;/span> &lt;span style="color:#06b6ef">init&lt;/span>(){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> URL.&lt;span style="color:#06b6ef">setURLStreamHandlerFactory&lt;/span>(&lt;span style="color:#815ba4">new&lt;/span> FsUrlStreamHandlerFactory());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String hiveSiteXmlPath &lt;span style="color:#5bc4bf">=&lt;/span> calHadoopXmlPath(hosts, &lt;span style="color:#48b685">&amp;#34;hive-site&amp;#34;&lt;/span>, &lt;span style="color:#815ba4">false&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> useSparkSql &lt;span style="color:#5bc4bf">=&lt;/span> hiveSiteXmlPath &lt;span style="color:#5bc4bf">!=&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.&lt;span style="color:#06b6ef">info&lt;/span>(&lt;span style="color:#48b685">&amp;#34;hive-site.xml文件({})存在:{}&amp;#34;&lt;/span>, hiveSiteXmlPath, useSparkSql);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> (useSparkSql) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String hiveMetaStoreUris &lt;span style="color:#5bc4bf">=&lt;/span> parseMetaStoreUri(hiveSiteXmlPath);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> (StringUtils.&lt;span style="color:#06b6ef">isNotEmpty&lt;/span>(hiveMetaStoreUris)) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.&lt;span style="color:#06b6ef">info&lt;/span>(&lt;span style="color:#48b685">&amp;#34;从hive-site.xml文件读取到{}={},并设置到环境变量&amp;#34;&lt;/span>, HIVE_METASTORE_URIS_KEY, hiveMetaStoreUris);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> System.&lt;span style="color:#06b6ef">setProperty&lt;/span>(HIVE_METASTORE_URIS_KEY, hiveMetaStoreUris);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> calHadoopXmlPath(hosts, &lt;span style="color:#48b685">&amp;#34;hive-site&amp;#34;&lt;/span>, &lt;span style="color:#815ba4">true&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> calHadoopXmlPath(hosts, &lt;span style="color:#48b685">&amp;#34;hdfs-site&amp;#34;&lt;/span>, &lt;span style="color:#815ba4">true&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } &lt;span style="color:#815ba4">else&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> useSparkSql &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">false&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> &lt;span style="color:#fec418">void&lt;/span> &lt;span style="color:#06b6ef">write&lt;/span>(){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> HiveContext hiveContext &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> HiveContext(sc); &lt;span style="color:#776e71">//别问我从哪来的SparkContext,示例代码，随意看看&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DataFrame docDataFrame &lt;span style="color:#5bc4bf">=&lt;/span> hiveContext.&lt;span style="color:#06b6ef">createDataFrame&lt;/span>(rowRdd, sparkSchema); &lt;span style="color:#776e71">//rdd和Schema也是，别问&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> docDataFrame.&lt;span style="color:#06b6ef">write&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .&lt;span style="color:#06b6ef">mode&lt;/span>(SaveMode.&lt;span style="color:#06b6ef">Overwrite&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> .&lt;span style="color:#06b6ef">saveAsTable&lt;/span>(&lt;span style="color:#48b685">&amp;#34;xxx.yyy&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">public&lt;/span> &lt;span style="color:#fec418">void&lt;/span> &lt;span style="color:#06b6ef">end&lt;/span>(){
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">synchronized&lt;/span> (Configuration.&lt;span style="color:#06b6ef">class&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Configuration tempalte &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> Configuration(&lt;span style="color:#815ba4">false&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CopyOnWriteArrayList&lt;span style="color:#5bc4bf">&amp;lt;&lt;/span>String&lt;span style="color:#5bc4bf">&amp;gt;&lt;/span> defaultResources &lt;span style="color:#5bc4bf">=&lt;/span> TestUtil.&lt;span style="color:#06b6ef">getPrivateField&lt;/span>(conf, &lt;span style="color:#48b685">&amp;#34;defaultResources&amp;#34;&lt;/span>); &lt;span style="color:#776e71">//getPrivateField方法如其名，递归父类拿到字段并设可见再读&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> (defaultResources &lt;span style="color:#5bc4bf">==&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">for&lt;/span> (String resource : extraDefaultResource) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> defaultResources.&lt;span style="color:#06b6ef">remove&lt;/span>(resource);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> WeakHashMap&lt;span style="color:#5bc4bf">&amp;lt;&lt;/span>Configuration, Object&lt;span style="color:#5bc4bf">&amp;gt;&lt;/span> REGISTRY &lt;span style="color:#5bc4bf">=&lt;/span> TestUtil.&lt;span style="color:#06b6ef">getPrivateField&lt;/span>(conf, &lt;span style="color:#48b685">&amp;#34;REGISTRY&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> (REGISTRY &lt;span style="color:#5bc4bf">==&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">return&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">for&lt;/span> (Configuration curConf : REGISTRY.&lt;span style="color:#06b6ef">keySet&lt;/span>()) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Boolean loadDefaults &lt;span style="color:#5bc4bf">=&lt;/span> TestUtil.&lt;span style="color:#06b6ef">getPrivateField&lt;/span>(curConf, &lt;span style="color:#48b685">&amp;#34;loadDefaults&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> (loadDefaults &lt;span style="color:#5bc4bf">!=&lt;/span> &lt;span style="color:#815ba4">null&lt;/span> &lt;span style="color:#5bc4bf">&amp;amp;&amp;amp;&lt;/span> loadDefaults) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> curConf.&lt;span style="color:#06b6ef">reloadConfiguration&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> String &lt;span style="color:#06b6ef">calHadoopXmlPath&lt;/span>(String hosts, String fileName, &lt;span style="color:#fec418">boolean&lt;/span> addToDefaultRs) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String hdfsPath &lt;span style="color:#5bc4bf">=&lt;/span> String.&lt;span style="color:#06b6ef">format&lt;/span>(&lt;span style="color:#48b685">&amp;#34;hdfs://%shive/%s-%s.xml&amp;#34;&lt;/span>, BASE_HDFS_PATH, hosts, fileName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">try&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> FileSystem fs &lt;span style="color:#5bc4bf">=&lt;/span> FileSystem.&lt;span style="color:#06b6ef">get&lt;/span>(&lt;span style="color:#815ba4">new&lt;/span> Configuration());
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> (HdfsUtil.&lt;span style="color:#06b6ef">isFileExist&lt;/span>(hdfsPath, fs)) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">if&lt;/span> (addToDefaultRs) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ClassLoader classLoader &lt;span style="color:#5bc4bf">=&lt;/span> Thread.&lt;span style="color:#06b6ef">currentThread&lt;/span>().&lt;span style="color:#06b6ef">getContextClassLoader&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> URL cpResource &lt;span style="color:#5bc4bf">=&lt;/span> classLoader.&lt;span style="color:#06b6ef">getResource&lt;/span>(&lt;span style="color:#48b685">&amp;#34;&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String cpDir &lt;span style="color:#5bc4bf">=&lt;/span> cpResource &lt;span style="color:#5bc4bf">!=&lt;/span> &lt;span style="color:#815ba4">null&lt;/span> &lt;span style="color:#5bc4bf">?&lt;/span> cpResource.&lt;span style="color:#06b6ef">getPath&lt;/span>() : (System.&lt;span style="color:#06b6ef">getProperty&lt;/span>(&lt;span style="color:#48b685">&amp;#34;user.dir&amp;#34;&lt;/span>) &lt;span style="color:#5bc4bf">+&lt;/span> File.&lt;span style="color:#06b6ef">separator&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String downloadFileName &lt;span style="color:#5bc4bf">=&lt;/span> String.&lt;span style="color:#06b6ef">format&lt;/span>(&lt;span style="color:#48b685">&amp;#34;%s-%s_%s.xml&amp;#34;&lt;/span>, hosts, fileName, System.&lt;span style="color:#06b6ef">currentTimeMillis&lt;/span>()); &lt;span style="color:#776e71">//实际下载本地的名字&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> String fullDownloadFilePath &lt;span style="color:#5bc4bf">=&lt;/span> cpDir &lt;span style="color:#5bc4bf">+&lt;/span> downloadFileName;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.&lt;span style="color:#06b6ef">info&lt;/span>(&lt;span style="color:#48b685">&amp;#34;增加Hadoop配置文件:{}到Configuration默认资源,下载到本地:{}&amp;#34;&lt;/span>, hdfsPath, fullDownloadFilePath);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">try&lt;/span> (OutputStream os &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> BufferedOutputStream(&lt;span style="color:#815ba4">new&lt;/span> FileOutputStream(fullDownloadFilePath))) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> HdfsUtil.&lt;span style="color:#06b6ef">copyFileAsStream&lt;/span>(hdfsPath, os, fs);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Configuration.&lt;span style="color:#06b6ef">addDefaultResource&lt;/span>(downloadFileName); &lt;span style="color:#776e71">//加入默认资源&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extraDefaultResource.&lt;span style="color:#06b6ef">add&lt;/span>(downloadFileName); &lt;span style="color:#776e71">//记录加过哪些默认资源，后面要移除&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } &lt;span style="color:#815ba4">catch&lt;/span> (Exception e) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log().&lt;span style="color:#06b6ef">error&lt;/span>(e.&lt;span style="color:#06b6ef">getMessage&lt;/span>(), e);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.&lt;span style="color:#06b6ef">info&lt;/span>(&lt;span style="color:#48b685">&amp;#34;增加Hadoop配置文件:{}后读取classLoader.getResource({})={}&amp;#34;&lt;/span>, fileName, downloadFileName, classLoader.&lt;span style="color:#06b6ef">getResource&lt;/span>(downloadFileName));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">return&lt;/span> hdfsPath;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } &lt;span style="color:#815ba4">else&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.&lt;span style="color:#06b6ef">info&lt;/span>(&lt;span style="color:#48b685">&amp;#34;不存在文件:{}&amp;#34;&lt;/span>, fileName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } &lt;span style="color:#815ba4">catch&lt;/span> (Exception e) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.&lt;span style="color:#06b6ef">error&lt;/span>(&lt;span style="color:#48b685">&amp;#34;get FileSystem fail!&amp;#34;&lt;/span>, e);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">return&lt;/span> &lt;span style="color:#815ba4">null&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">private&lt;/span> String &lt;span style="color:#06b6ef">parseMetaStoreUri&lt;/span>(String hiveSiteXmlPath) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Configuration conf &lt;span style="color:#5bc4bf">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> Configuration(&lt;span style="color:#815ba4">false&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">try&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conf.&lt;span style="color:#06b6ef">addResource&lt;/span>(&lt;span style="color:#815ba4">new&lt;/span> URL(hiveSiteXmlPath));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> } &lt;span style="color:#815ba4">catch&lt;/span> (IOException e) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> e.&lt;span style="color:#06b6ef">printStackTrace&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">return&lt;/span> conf.&lt;span style="color:#06b6ef">get&lt;/span>(HIVE_METASTORE_URIS_KEY);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Kerberos集群的Sqoop,Hive,HBase,Kafka,Maxwell使用</title><link>https://leibnizhu.github.io/p/Kerberos%E9%9B%86%E7%BE%A4%E7%9A%84SqoopHiveHBaseKafkaMaxwell%E4%BD%BF%E7%94%A8/</link><pubDate>Wed, 07 Mar 2018 16:23:56 +0800</pubDate><guid>https://leibnizhu.github.io/p/Kerberos%E9%9B%86%E7%BE%A4%E7%9A%84SqoopHiveHBaseKafkaMaxwell%E4%BD%BF%E7%94%A8/</guid><description>&lt;img src="https://leibnizhu.github.io/p/Kerberos%E9%9B%86%E7%BE%A4%E7%9A%84SqoopHiveHBaseKafkaMaxwell%E4%BD%BF%E7%94%A8/flower.jpg" alt="Featured image of post Kerberos集群的Sqoop,Hive,HBase,Kafka,Maxwell使用" />&lt;p>介绍在部署了Kerberos的安全Hadoop集群中, Sqoop,Hive,HBase,Kafka,Maxwell使用方法.&lt;/p>
&lt;h2 id="sqoop使用">Sqoop使用&lt;/h2>
&lt;p>配置好Kerberos之后, sqoop不能直接使用, 需要进行一些配置:&lt;/p>
&lt;ol>
&lt;li>分配sqoop的组, 执行&lt;code>usermod -a -G hdfs sqoop&lt;/code>加入到hdfs组, 使用&lt;code>groups sqoop&lt;/code>确认执行成功;&lt;/li>
&lt;li>进入Hue的用户管理界面, 新增sqoop用户, 在hdfs用户组中;&lt;/li>
&lt;li>在Hue的HDFS文件管理页面中, 创建/user/sqoop目录, 从属于sqoop:hdfs用户/用户组;&lt;/li>
&lt;li>进入cdh1, 创建Kerberos用户, 名为sqoop, 可以导出keytab;&lt;/li>
&lt;li>使用kinit命令切换到sqoop用户(在脚本中可以使用keytab切换)&lt;/li>
&lt;li>执行sqoop命令&lt;/li>
&lt;/ol>
&lt;h2 id="spark访问hbase">Spark访问HBase&lt;/h2>
&lt;ol>
&lt;li>进入cdh1, 创建Kerberos用户, 名为hbase; 导出keytab, 名为hbase.keytab, 保存到本地;&lt;/li>
&lt;li>下载krb5.conf到本地.&lt;/li>
&lt;li>创建测试类, 并执行, 代码如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">/*HBase测试*/&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">object&lt;/span> &lt;span style="color:#fec418">KerberosHBaseTest&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> main&lt;span style="color:#5bc4bf">(&lt;/span>args&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Array&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">])&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> zkHosts &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;cdh2:2181,cdh3:2181,cdh4:2181&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//krb5.conf本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkConf&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>setAppName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosHBaseTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>setMaster&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> sc &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkContext&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//配置HBase连接
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> hbaseConfig &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">HBaseConfiguration&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>create&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.zookeeper.quorum&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> zkHosts&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;zookeeper.znode.parent&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/hbase&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//设置集群和hbase的安全模式为kerberos
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hadoop.security.authentication&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;kerberos&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.security.authentication&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;kerberos&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.master.kerberos.principal&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;hbase/_HOST@TURINGDI.COM&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//没有似乎也行
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> hbaseConfig&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase.regionserver.kerberos.principal&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;hbase/_HOST@TURINGDI.COM&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setConfiguration&lt;span style="color:#5bc4bf">(&lt;/span>hbaseConfig&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>loginUserFromKeytab&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/hbase.keytab&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//Kerberos用户名, keytab本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">//设置广播变量，解决序列化问题
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">//HBase配置
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> broadcastHBaseConf &lt;span style="color:#815ba4">=&lt;/span> sc&lt;span style="color:#5bc4bf">.&lt;/span>broadcast&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SerializableWritable&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>hbaseConfig&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">//HBase连接工具类
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> hbaseConnection &lt;span style="color:#815ba4">=&lt;/span> sc&lt;span style="color:#5bc4bf">.&lt;/span>broadcast&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">HBaseConnection&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>broadcastHBaseConf&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> result &lt;span style="color:#815ba4">=&lt;/span> scanByStartTimestamp&lt;span style="color:#5bc4bf">(&lt;/span>hbaseConnection&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;t1&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#f99b15">0L&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result&lt;span style="color:#5bc4bf">.&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>r &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> println&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">ConvertService&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>convertResultToHBaseRow&lt;span style="color:#5bc4bf">(&lt;/span>r&lt;span style="color:#5bc4bf">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sc&lt;span style="color:#5bc4bf">.&lt;/span>stop&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">/**
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * 从HBase中scan指定表的所有列，从指定的时间戳开始
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> *
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param hBaseConnection HBase连接
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param tableName 表名
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @param starTimestamp 开始scan的时间戳，从该时间戳scan到当前时间
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @return scan的结果，Result的List
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> * @author Leibniz
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71"> */&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> scanByStartTimestamp&lt;span style="color:#5bc4bf">(&lt;/span>hBaseConnection&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Broadcast&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">HBaseConnection&lt;/span>&lt;span style="color:#5bc4bf">],&lt;/span> tableName&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> starTimestamp&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Long&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">ArrayBuffer&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">Result&lt;/span>&lt;span style="color:#5bc4bf">]&lt;/span> &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> resultList &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">ArrayBuffer&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">Result&lt;/span>&lt;span style="color:#5bc4bf">]()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">Try&lt;/span>&lt;span style="color:#5bc4bf">({&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> scan &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">Scan&lt;/span>&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scan&lt;span style="color:#5bc4bf">.&lt;/span>setTimeRange&lt;span style="color:#5bc4bf">(&lt;/span>starTimestamp&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>currentTimeMillis&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 获取表
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> table &lt;span style="color:#815ba4">=&lt;/span> hBaseConnection&lt;span style="color:#5bc4bf">.&lt;/span>value&lt;span style="color:#5bc4bf">.&lt;/span>connection&lt;span style="color:#5bc4bf">.&lt;/span>getTable&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#fec418">TableName&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>valueOf&lt;span style="color:#5bc4bf">(&lt;/span>tableName&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> table&lt;span style="color:#5bc4bf">.&lt;/span>getScanner&lt;span style="color:#5bc4bf">(&lt;/span>scan&lt;span style="color:#5bc4bf">).&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>resultList&lt;span style="color:#5bc4bf">.+=)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}).&lt;/span>recover&lt;span style="color:#5bc4bf">({&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">case&lt;/span> e&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Throwable&lt;/span> &lt;span style="color:#5bc4bf">=&amp;gt;&lt;/span> log&lt;span style="color:#5bc4bf">.&lt;/span>error&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;从HBase表{}中按时间戳({}-&amp;gt;NOW)scan时抛出异常:{}&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">Seq&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">AnyRef&lt;/span>&lt;span style="color:#5bc4bf">](&lt;/span>tableName&lt;span style="color:#5bc4bf">,&lt;/span> starTimestamp&lt;span style="color:#5bc4bf">.&lt;/span>toString&lt;span style="color:#5bc4bf">,&lt;/span> e&lt;span style="color:#5bc4bf">.&lt;/span>getMessage&lt;span style="color:#5bc4bf">)&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#815ba4">_&lt;/span>&lt;span style="color:#fec418">*&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resultList
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="spark访问hive">Spark访问Hive&lt;/h2>
&lt;ol>
&lt;li>Hive可以沿用hbase的Kerberos用户, 也可以新建一个Hive用户及其对应keytab文件.&lt;/li>
&lt;li>本地测试请将集群的&lt;code>hive-site.xml&lt;/code>导出并保存在项目的&lt;code>src/main/resources/&lt;/code>目录下;&lt;/li>
&lt;li>编写Spark测试程序:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">/*Hive测试*/&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">object&lt;/span> &lt;span style="color:#fec418">KerberosHiveTest&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> main&lt;span style="color:#5bc4bf">(&lt;/span>args&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Array&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">])&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//krb5.conf本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkConf&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>setAppName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosHiveTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>setMaster&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> sc &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkContext&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> config &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">HBaseConfiguration&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>create&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> config&lt;span style="color:#5bc4bf">.&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hadoop.security.authentication&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;kerberos&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setConfiguration&lt;span style="color:#5bc4bf">(&lt;/span>config&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">UserGroupInformation&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>loginUserFromKeytab&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;hbase&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/hbase.keytab&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//Kerberos用户名, keytab本地路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkSession &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">SparkSession&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>builder&lt;span style="color:#5bc4bf">.&lt;/span>master&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>appName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosHiveTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>enableHiveSupport&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">.&lt;/span>config&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;yarn.resourcemanager.principal&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;rm/_HOST@TURINGDI.COM&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// .config(&amp;#34;spark.yarn.keytab&amp;#34;, &amp;#34;/path/to/hbase.keytab&amp;#34;)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// .config(&amp;#34;spark.yarn.principal&amp;#34;, &amp;#34;hbase@TURINGDI.COM&amp;#34;)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#5bc4bf">.&lt;/span>getOrCreate&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> dataFrame &lt;span style="color:#815ba4">=&lt;/span> sparkSession&lt;span style="color:#5bc4bf">.&lt;/span>sql&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;select * from hivetest2&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dataFrame&lt;span style="color:#5bc4bf">.&lt;/span>rdd&lt;span style="color:#5bc4bf">.&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>row &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> println&lt;span style="color:#5bc4bf">(&lt;/span>row&lt;span style="color:#5bc4bf">.&lt;/span>getInt&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">0&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34; -&amp;gt; &amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> row&lt;span style="color:#5bc4bf">.&lt;/span>getString&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">1&lt;/span>&lt;span style="color:#5bc4bf">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sc&lt;span style="color:#5bc4bf">.&lt;/span>stop&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="spark访问kafka">Spark访问Kafka&lt;/h2>
&lt;ol>
&lt;li>进入Cloudera Manager的Kafka配置页面, 搜索&amp;rsquo;Inter Broker Protocol&amp;rsquo;, 更改为&amp;rsquo;SASL_PLAINTEXT';&lt;/li>
&lt;li>重启Kafka配置;&lt;/li>
&lt;li>进入cdh1, 创建Kerberos用户, 名为kafka; 导出keytab, 名为kafka.keytab, 并保存到本地(测试用);&lt;/li>
&lt;li>cdh1中新建一个jaas.conf配置文件, 并复制到本地(注意修改keyTab), 内容如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>KafkaClient &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> com.sun.security.auth.module.Krb5LoginModule required
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">doNotPrompt&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">useTicketCache&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">useKeyTab&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">principal&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;kafka@TURINGDI.COM&amp;#34;&lt;/span> &lt;span style="color:#776e71">#根据实际修改&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">serviceName&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;kafka&amp;#34;&lt;/span> &lt;span style="color:#776e71">## 固定&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">client&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ef6155">keyTab&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;/path/to/kafka.keytab&amp;#34;&lt;/span>; &lt;span style="color:#776e71">## keytab路径,节点和本地按实际路径填写&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="5">
&lt;li>cdh1中新建一个kafka.properties文件, 内容如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-fallback" data-lang="fallback">&lt;span style="display:flex;">&lt;span>security.protocol=SASL_PLAINTEXT
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sasl.kerberos.service.name=kafka
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sasl.mechanism=GSSAPI
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>security.inter.broker.protocol=SASL_PLAINTEXT
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="6">
&lt;li>编写Spark程序进行测试:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-scala" data-lang="scala">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#815ba4">object&lt;/span> &lt;span style="color:#fec418">KerberosKafkaTest&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">def&lt;/span> main&lt;span style="color:#5bc4bf">(&lt;/span>args&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">Array&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>&lt;span style="color:#5bc4bf">])&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> zkHosts &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;cdh2:2181,cdh3:2181,cdh4:2181&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> kafkaBrokers &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#48b685">&amp;#34;cdh2:9092,cdh3:9092,cdh4:9092&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> topics &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">List&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;maxwell&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/krb5.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//本地krb5.conf路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#fec418">System&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>setProperty&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;java.security.auth.login.config&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#48b685">&amp;#34;/path/to/jaas.conf&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>&lt;span style="color:#776e71">//本地jaas.conf路径
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// 创建流处理上下文，并以启动参数指定的秒数为时间间隔做一次批处理。
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> sparkConf &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">SparkConf&lt;/span>&lt;span style="color:#5bc4bf">().&lt;/span>setAppName&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;KerberosKafkaTest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>set&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;spark.streaming.kafka.consumer.poll.ms&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">KAFKA_CONSUMER_POLL_MS&lt;/span>&lt;span style="color:#5bc4bf">).&lt;/span>setMaster&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;local&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#815ba4">val&lt;/span> ssc &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#815ba4">new&lt;/span> &lt;span style="color:#fec418">StreamingContext&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>sparkConf&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">Seconds&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#f99b15">10&lt;/span>&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#776e71">// 配置并创建Kafka输入流
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// 如果zookeeper没有offset值或offset值超出范围，就给个初始的offset
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#776e71">// 有earliest、largest可选，分别表示给当前最小的offset、当前最大的offset。默认largest
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> kafkaParams &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">Map&lt;/span>&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">String&lt;/span>, &lt;span style="color:#fec418">Object&lt;/span>&lt;span style="color:#5bc4bf">](&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;auto.offset.reset&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;earliest&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;bootstrap.servers&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> kafkaBrokers&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;group.id&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;testGroup&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;enable.auto.commit&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#815ba4">false&lt;/span>&lt;span style="color:#815ba4">:&lt;/span> &lt;span style="color:#fec418">java.lang.Boolean&lt;/span>&lt;span style="color:#5bc4bf">),&lt;/span> &lt;span style="color:#776e71">//禁用自动提交Offset，否则可能没正常消费完就提交了，造成数据错误
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#48b685">&amp;#34;key.deserializer&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> classOf&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">StringDeserializer&lt;/span>&lt;span style="color:#5bc4bf">],&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;value.deserializer&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> classOf&lt;span style="color:#5bc4bf">[&lt;/span>&lt;span style="color:#fec418">StringDeserializer&lt;/span>&lt;span style="color:#5bc4bf">],&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#48b685">&amp;#34;sasl.kerberos.service.name&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;kafka&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#776e71">//必须有
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#48b685">&amp;#34;security.protocol&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">-&amp;gt;&lt;/span> &lt;span style="color:#48b685">&amp;#34;SASL_PLAINTEXT&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">)&lt;/span> &lt;span style="color:#776e71">//与Kafka配置一致
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#776e71">&lt;/span> &lt;span style="color:#815ba4">val&lt;/span> kafkaStream &lt;span style="color:#815ba4">=&lt;/span> &lt;span style="color:#fec418">KafkaUtils&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>createDirectStream&lt;span style="color:#5bc4bf">(&lt;/span>ssc&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">PreferConsistent&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> &lt;span style="color:#fec418">ConsumerStrategies&lt;/span>&lt;span style="color:#5bc4bf">.&lt;/span>&lt;span style="color:#fec418">Subscribe&lt;/span>&lt;span style="color:#5bc4bf">(&lt;/span>topics&lt;span style="color:#5bc4bf">,&lt;/span> kafkaParams&lt;span style="color:#5bc4bf">))&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kafkaStream&lt;span style="color:#5bc4bf">.&lt;/span>foreachRDD&lt;span style="color:#5bc4bf">(&lt;/span>rdd &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log&lt;span style="color:#5bc4bf">.&lt;/span>info&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;接收到{}条Kafka消息&amp;#34;&lt;/span>&lt;span style="color:#5bc4bf">,&lt;/span> rdd&lt;span style="color:#5bc4bf">.&lt;/span>count&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rdd&lt;span style="color:#5bc4bf">.&lt;/span>foreach&lt;span style="color:#5bc4bf">(&lt;/span>message &lt;span style="color:#815ba4">=&amp;gt;&lt;/span> &lt;span style="color:#5bc4bf">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> println&lt;span style="color:#5bc4bf">(&lt;/span>&lt;span style="color:#48b685">&amp;#34;partition=&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> message&lt;span style="color:#5bc4bf">.&lt;/span>partition &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;, value=&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> message&lt;span style="color:#5bc4bf">.&lt;/span>value &lt;span style="color:#5bc4bf">+&lt;/span> &lt;span style="color:#48b685">&amp;#34;, offset=&amp;#34;&lt;/span> &lt;span style="color:#5bc4bf">+&lt;/span> message&lt;span style="color:#5bc4bf">.&lt;/span>offset&lt;span style="color:#5bc4bf">.&lt;/span>toString&lt;span style="color:#5bc4bf">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">})&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ssc&lt;span style="color:#5bc4bf">.&lt;/span>start&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ssc&lt;span style="color:#5bc4bf">.&lt;/span>awaitTermination&lt;span style="color:#5bc4bf">()&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#5bc4bf">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="7">
&lt;li>kafka自带的命令, 如kafka-console-consumer, kafka-topics还不能使用, 若要使用, 需要先执行:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>export &lt;span style="color:#ef6155">KAFKA_OPTS&lt;/span>&lt;span style="color:#5bc4bf">=&lt;/span>&lt;span style="color:#48b685">&amp;#34;-Djava.security.krb5.conf=/etc/krb5.conf -Djava.security.auth.login.config=/path/to/jaas.conf&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意修改其中的jass.conf路径, 并确保其中配置的keytab存在; 再执行相应的kafka命令.&lt;br>
如果觉得麻烦, 也可以编辑&lt;code>/opt/cloudera/parcels/KAFKA-3.0.0-1.3.0.0.p0.40/lib/kafka/bin/kafka-run-class.sh&lt;/code>, 在&lt;code>exec $JAVA&lt;/code>后面增加:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>-Djava.security.krb5.conf&lt;span style="color:#5bc4bf">=&lt;/span>/etc/krb5.conf -Djava.security.auth.login.config&lt;span style="color:#5bc4bf">=&lt;/span>/root/jaas.conf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="maxwell配置">Maxwell配置&lt;/h2>
&lt;ol>
&lt;li>编辑${MAXWELL_HOME}/bin/maxwell, 在文件尾部附件的&lt;code>exec $JAVA $JAVA_OPTS&lt;/code>后面增加:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>-Djava.security.krb5.conf&lt;span style="color:#5bc4bf">=&lt;/span>/etc/krb5.conf -Djava.security.auth.login.config&lt;span style="color:#5bc4bf">=&lt;/span>/root/jaas.conf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>编辑一个config.properties文件, 内容如下:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-fallback" data-lang="fallback">&lt;span style="display:flex;">&lt;span>kafka.security.protocol=SASL_PLAINTEXT
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kafka.sasl.kerberos.service.name=kafka
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kafka.sasl.mechanism=GSSAPI
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>security.inter.broker.protocol=SASL_PLAINTEXT
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sasl.mechanism.inter.broker.protocol=PLAIN
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>在maxwell启动命令中增加参数:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#e7e9db;background-color:#2f1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>--config /path/to/config.properties
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>